{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"OCRganizer Documentation","text":"<p>Welcome to the OCRganizer documentation. This comprehensive guide will help you understand, install, configure, and use the system effectively.</p>"},{"location":"#overview","title":"Overview","text":"<p>The OCRganizer is an AI-powered document management system that automatically categorizes, renames, and organizes PDF documents using advanced text extraction and AI analysis.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Multi-Provider AI Support: Works with OpenAI GPT, Anthropic Claude, or local LM Studio</li> <li>Robust Text Extraction: Handles both digital and scanned PDFs with OCR fallback</li> <li>Intelligent Organization: Creates structured folder hierarchies</li> <li>Smart Naming: Generates descriptive filenames</li> <li>Dual Interface: Web UI and command-line support</li> <li>Privacy-First: Optional local processing</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Clone and setup\ngit clone https://github.com/yourusername/OCRganizer.git\ncd OCRganizer\n\n# Install dependencies\npip install -e .[dev]\n\n# Configure environment\ncp env.example env\n# Edit env file with your AI provider credentials\n\n# Run the web interface\npython app.py\n# Visit http://localhost:5000\n</code></pre>"},{"location":"#architecture","title":"Architecture","text":"graph TD     A[PDF Input] --&gt; B[Text Extraction]     B --&gt; C[AI Analysis]     C --&gt; D[File Organization]     D --&gt; E[Organized Files]      B --&gt; F[pypdf]     B --&gt; G[OCR/Tesseract]      C --&gt; H[OpenAI GPT]     C --&gt; I[Anthropic Claude]     C --&gt; J[Local LM Studio]"},{"location":"#documentation","title":"Documentation","text":""},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Quick Start - Get running in 5 minutes</li> <li>Installation Guide - Complete setup instructions</li> <li>User Guide - How to use the system</li> <li>CLI Usage - Command-line interface guide</li> </ul>"},{"location":"#ai-providers","title":"AI Providers","text":"<ul> <li>AI Provider Setup - Detailed setup for OpenAI, Anthropic, and LM Studio</li> <li>Configuration Reference - Detailed configuration options</li> <li>LM Studio Setup - Local AI setup guide</li> </ul>"},{"location":"#development","title":"Development","text":"<ul> <li>Developer Guide - Comprehensive developer documentation</li> <li>API Reference - Developer API documentation</li> <li>Improvements - Project improvement history</li> </ul>"},{"location":"#support","title":"Support","text":"<ul> <li>Troubleshooting - Common issues and solutions</li> </ul>"},{"location":"ai-provider-setup/","title":"AI Provider Setup Guide","text":"<p>This guide provides detailed instructions for setting up each AI provider with the OCRganizer system.</p>"},{"location":"ai-provider-setup/#openai-setup","title":"OpenAI Setup","text":""},{"location":"ai-provider-setup/#1-create-openai-account","title":"1. Create OpenAI Account","text":"<ol> <li>Visit OpenAI: Go to https://platform.openai.com</li> <li>Sign Up: Create an account or sign in</li> <li>Verify Email: Check your email and verify your account</li> </ol>"},{"location":"ai-provider-setup/#2-get-api-key","title":"2. Get API Key","text":"<ol> <li>Navigate to API Keys: Go to https://platform.openai.com/api-keys</li> <li>Create New Key: Click \"Create new secret key\"</li> <li>Name Your Key: Give it a descriptive name (e.g., \"PDF-Categorizer\")</li> <li>Copy the Key: Important: Copy the key immediately - you won't be able to see it again</li> <li>Save Securely: Store the key in a password manager or secure location</li> </ol>"},{"location":"ai-provider-setup/#3-add-billing-information","title":"3. Add Billing Information","text":"<ol> <li>Go to Billing: Navigate to https://platform.openai.com/account/billing</li> <li>Add Payment Method: Add a credit card or PayPal account</li> <li>Set Usage Limits: Consider setting monthly spending limits for cost control</li> </ol>"},{"location":"ai-provider-setup/#4-configure-in-ocrganizer","title":"4. Configure in OCRganizer","text":"<pre><code># Edit your env file\nnano env\n\n# Add your OpenAI API key\nOPENAI_API_KEY=sk-your-actual-api-key-here\n</code></pre>"},{"location":"ai-provider-setup/#5-test-the-setup","title":"5. Test the Setup","text":"<pre><code># Test OpenAI connection\npython -c \"\nfrom src.ai_analyzer import AIAnalyzer\nanalyzer = AIAnalyzer(provider='openai')\nprint('\u2705 OpenAI connection successful!')\n\"\n</code></pre>"},{"location":"ai-provider-setup/#cost-information","title":"Cost Information","text":"<ul> <li>GPT-3.5-turbo: ~$0.002 per 1K tokens (very affordable)</li> <li>GPT-4: ~$0.03 per 1K tokens (higher quality, more expensive)</li> <li>Typical cost: $0.01-0.05 per PDF document</li> </ul>"},{"location":"ai-provider-setup/#anthropic-claude-setup","title":"Anthropic Claude Setup","text":""},{"location":"ai-provider-setup/#1-create-anthropic-account","title":"1. Create Anthropic Account","text":"<ol> <li>Visit Anthropic: Go to https://console.anthropic.com</li> <li>Sign Up: Create an account with your email</li> <li>Verify Email: Check your email and verify your account</li> </ol>"},{"location":"ai-provider-setup/#2-get-api-key_1","title":"2. Get API Key","text":"<ol> <li>Navigate to API Keys: Go to https://console.anthropic.com/keys</li> <li>Create New Key: Click \"Create Key\"</li> <li>Name Your Key: Give it a descriptive name (e.g., \"PDF-Categorizer\")</li> <li>Copy the Key: Important: Copy the key immediately - you won't be able to see it again</li> <li>Save Securely: Store the key in a password manager</li> </ol>"},{"location":"ai-provider-setup/#3-add-billing-information_1","title":"3. Add Billing Information","text":"<ol> <li>Go to Billing: Navigate to https://console.anthropic.com/billing</li> <li>Add Payment Method: Add a credit card</li> <li>Set Usage Limits: Consider setting monthly spending limits</li> </ol>"},{"location":"ai-provider-setup/#4-configure-in-ocrganizer_1","title":"4. Configure in OCRganizer","text":"<pre><code># Edit your env file\nnano env\n\n# Add your Anthropic API key\nANTHROPIC_API_KEY=sk-ant-your-actual-api-key-here\n</code></pre>"},{"location":"ai-provider-setup/#5-test-the-setup_1","title":"5. Test the Setup","text":"<pre><code># Test Anthropic connection\npython -c \"\nfrom src.ai_analyzer import AIAnalyzer\nanalyzer = AIAnalyzer(provider='anthropic')\nprint('\u2705 Anthropic connection successful!')\n\"\n</code></pre>"},{"location":"ai-provider-setup/#cost-information_1","title":"Cost Information","text":"<ul> <li>Claude 3 Haiku: ~$0.25 per 1M tokens (very affordable)</li> <li>Claude 3 Sonnet: ~$3 per 1M tokens (high quality)</li> <li>Claude 3 Opus: ~$15 per 1M tokens (highest quality)</li> <li>Typical cost: $0.01-0.10 per PDF document</li> </ul>"},{"location":"ai-provider-setup/#lm-studio-setup-localfree","title":"LM Studio Setup (Local/Free)","text":""},{"location":"ai-provider-setup/#1-download-lm-studio","title":"1. Download LM Studio","text":"<ol> <li>Visit LM Studio: Go to https://lmstudio.ai</li> <li>Download: Download the desktop application for your OS</li> <li>Install: Follow the installation instructions</li> </ol>"},{"location":"ai-provider-setup/#2-download-a-model","title":"2. Download a Model","text":"<ol> <li>Open LM Studio: Launch the application</li> <li>Go to Models: Click on the \"Models\" tab</li> <li>Search for Models: Look for these recommended models:</li> <li>Llama 2 7B Chat (good balance)</li> <li>Mistral 7B Instruct (excellent for instructions)</li> <li>Code Llama 7B (good for structured output)</li> </ol>"},{"location":"ai-provider-setup/#3-load-and-start-server","title":"3. Load and Start Server","text":"<ol> <li>Load Model: Click on a model to download and load it</li> <li>Start Server: Go to \"Local Server\" tab</li> <li>Click \"Start Server\": The server will start on port 1234</li> <li>Note Model Name: Copy the exact model name shown</li> </ol>"},{"location":"ai-provider-setup/#4-configure-in-ocrganizer_2","title":"4. Configure in OCRganizer","text":"<pre><code># Edit your env file\nnano env\n\n# Configure LM Studio\nOPENAI_BASE_URL=http://localhost:1234/v1\nOPENAI_API_KEY=lm-studio\nLOCAL_MODEL_NAME=your-actual-model-name-here\n</code></pre>"},{"location":"ai-provider-setup/#5-test-the-setup_2","title":"5. Test the Setup","text":"<pre><code># Test LM Studio connection\npython -c \"\nfrom src.ai_analyzer import AIAnalyzer\nanalyzer = AIAnalyzer(provider='lm_studio')\nprint('\u2705 LM Studio connection successful!')\n\"\n</code></pre>"},{"location":"ai-provider-setup/#cost-information_2","title":"Cost Information","text":"<ul> <li>Free: No API costs</li> <li>Hardware: Requires sufficient RAM (8GB+ recommended)</li> <li>Performance: Slower than cloud APIs but completely private</li> </ul>"},{"location":"ai-provider-setup/#provider-comparison","title":"Provider Comparison","text":"Provider Cost Speed Privacy Quality Best For OpenAI $ Fast Cloud High Production use Anthropic $$ Fast Cloud Very High High-quality analysis LM Studio Free Slow Local Good Privacy-sensitive docs"},{"location":"ai-provider-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"ai-provider-setup/#openai-issues","title":"OpenAI Issues","text":"<p>Error: \"Invalid API key\" - Check the key format (should start with <code>sk-</code>) - Ensure the key is active in your OpenAI account - Verify billing information is added</p> <p>Error: \"Insufficient quota\" - Check your usage limits in OpenAI dashboard - Add more credits to your account - Consider upgrading your plan</p>"},{"location":"ai-provider-setup/#anthropic-issues","title":"Anthropic Issues","text":"<p>Error: \"Invalid API key\" - Check the key format (should start with <code>sk-ant-</code>) - Ensure the key is active in your Anthropic account - Verify billing information is added</p> <p>Error: \"Rate limit exceeded\" - Anthropic has rate limits for new accounts - Wait a few minutes and try again - Consider upgrading your plan</p>"},{"location":"ai-provider-setup/#lm-studio-issues","title":"LM Studio Issues","text":"<p>Error: \"Connection refused\" - Ensure LM Studio server is running - Check the port number (default: 1234) - Verify firewall settings</p> <p>Error: \"Model not found\" - Check the exact model name in LM Studio - Ensure the model is fully loaded - Try restarting the LM Studio server</p>"},{"location":"ai-provider-setup/#security-best-practices","title":"Security Best Practices","text":""},{"location":"ai-provider-setup/#api-key-security","title":"API Key Security","text":"<ol> <li>Never commit keys to version control</li> <li>Use environment variables</li> <li>Rotate keys regularly</li> <li>Use different keys for different environments</li> <li>Monitor usage and set alerts</li> </ol>"},{"location":"ai-provider-setup/#example-secure-setup","title":"Example Secure Setup","text":"<pre><code># .env file (never commit this)\nOPENAI_API_KEY=sk-your-secret-key-here\nANTHROPIC_API_KEY=sk-ant-your-secret-key-here\n\n# .env.example file (commit this)\nOPENAI_API_KEY=your_openai_api_key_here\nANTHROPIC_API_KEY=your_anthropic_api_key_here\n</code></pre>"},{"location":"ai-provider-setup/#cost-optimization-tips","title":"Cost Optimization Tips","text":""},{"location":"ai-provider-setup/#openai-optimization","title":"OpenAI Optimization","text":"<ul> <li>Use GPT-3.5-turbo for most documents (cheaper)</li> <li>Use GPT-4 only for complex documents</li> <li>Set usage limits to control costs</li> <li>Monitor usage in the OpenAI dashboard</li> </ul>"},{"location":"ai-provider-setup/#anthropic-optimization","title":"Anthropic Optimization","text":"<ul> <li>Use Claude 3 Haiku for simple documents</li> <li>Use Claude 3 Sonnet for complex analysis</li> <li>Set usage limits to control costs</li> <li>Monitor usage in the Anthropic console</li> </ul>"},{"location":"ai-provider-setup/#lm-studio-optimization","title":"LM Studio Optimization","text":"<ul> <li>Use smaller models for faster processing</li> <li>Close other applications to free up RAM</li> <li>Use GPU acceleration if available</li> <li>Consider model quantization for memory efficiency</li> </ul>"},{"location":"ai-provider-setup/#next-steps","title":"Next Steps","text":"<p>After setting up your AI provider:</p> <ol> <li>Test with sample documents: Use the test PDFs in <code>input_pdfs/</code></li> <li>Configure organization patterns: Customize folder structures</li> <li>Set up monitoring: Monitor costs and usage</li> <li>Optimize settings: Adjust confidence thresholds and batch sizes</li> </ol>"},{"location":"ai-provider-setup/#support","title":"Support","text":"<ul> <li>OpenAI Support: https://help.openai.com</li> <li>Anthropic Support: https://support.anthropic.com</li> <li>LM Studio Support: https://lmstudio.ai/docs</li> <li>Project Issues: GitHub Issues</li> </ul>"},{"location":"api/","title":"API Documentation","text":"<p>This document provides detailed information about the OCRganizer API and developer interfaces.</p>"},{"location":"api/#core-modules","title":"Core Modules","text":""},{"location":"api/#ai-analyzer-srcai_analyzer","title":"AI Analyzer (<code>src.ai_analyzer</code>)","text":"<p>The AI Analyzer module provides document analysis capabilities using various AI providers.</p>"},{"location":"api/#classes","title":"Classes","text":""},{"location":"api/#aianalyzer","title":"<code>AIAnalyzer</code>","text":"<p>Main class for document analysis.</p> <pre><code>from src.ai_analyzer import AIAnalyzer\n\n# Initialize with OpenAI\nanalyzer = AIAnalyzer(provider='openai')\n\n# Initialize with Anthropic\nanalyzer = AIAnalyzer(provider='anthropic')\n\n# Initialize with LM Studio\nanalyzer = AIAnalyzer(provider='lm_studio')\n</code></pre> <p>Methods:</p> <ul> <li><code>analyze_document(document: PDFDocument) -&gt; DocumentInfo</code></li> <li><code>get_provider_info() -&gt; Dict[str, Any]</code></li> </ul>"},{"location":"api/#documentinfo","title":"<code>DocumentInfo</code>","text":"<p>Data class for document analysis results.</p> <pre><code>from src.ai_analyzer import DocumentInfo\nfrom datetime import date\n\ninfo = DocumentInfo(\n    company_name=\"Chase Bank\",\n    document_type=\"bank statement\",\n    date=date(2023, 5, 15),\n    confidence_score=0.95,\n    suggested_name=\"Chase Bank Statement 2023-05-15\",\n    additional_metadata={\"account_type\": \"checking\"}\n)\n</code></pre> <p>Attributes: - <code>company_name: str</code> - Company/organization name - <code>document_type: str</code> - Type of document - <code>date: Optional[date]</code> - Document date - <code>confidence_score: float</code> - AI confidence (0.0-1.0) - <code>suggested_name: str</code> - Suggested filename - <code>additional_metadata: Dict[str, Any]</code> - Additional information</p>"},{"location":"api/#pdf-processor-srcpdf_processor","title":"PDF Processor (<code>src.pdf_processor</code>)","text":"<p>The PDF Processor module handles text extraction from PDF documents.</p>"},{"location":"api/#classes_1","title":"Classes","text":""},{"location":"api/#pdfprocessor","title":"<code>PDFProcessor</code>","text":"<p>Main class for PDF processing.</p> <pre><code>from src.pdf_processor import PDFProcessor\n\nprocessor = PDFProcessor()\n</code></pre> <p>Methods:</p> <ul> <li><code>process_pdf(file_path: Path) -&gt; PDFDocument</code></li> <li><code>extract_text_pypdf(pdf_path: Path) -&gt; str</code></li> <li><code>extract_text_pdfplumber(pdf_path: Path) -&gt; str</code></li> <li><code>extract_text_ocr(pdf_path: Path) -&gt; str</code></li> </ul>"},{"location":"api/#pdfdocument","title":"<code>PDFDocument</code>","text":"<p>Data class for processed PDF documents.</p> <pre><code>from src.pdf_processor import PDFDocument\nfrom pathlib import Path\n\ndoc = PDFDocument(\n    file_path=Path(\"document.pdf\"),\n    text_content=\"Extracted text content\",\n    metadata={\"title\": \"Document Title\"},\n    page_count=5,\n    extraction_method=\"pypdf\"\n)\n</code></pre> <p>Attributes: - <code>file_path: Path</code> - Path to the PDF file - <code>text_content: str</code> - Extracted text content - <code>metadata: Dict[str, Any]</code> - PDF metadata - <code>page_count: int</code> - Number of pages - <code>extraction_method: str</code> - Method used for extraction</p>"},{"location":"api/#file-organizer-srcfile_organizer","title":"File Organizer (<code>src.file_organizer</code>)","text":"<p>The File Organizer module handles file organization and naming.</p>"},{"location":"api/#classes_2","title":"Classes","text":""},{"location":"api/#fileorganizer","title":"<code>FileOrganizer</code>","text":"<p>Main class for file organization.</p> <pre><code>from src.file_organizer import FileOrganizer\n\norganizer = FileOrganizer()\n</code></pre> <p>Methods:</p> <ul> <li><code>organize_file(document_info: DocumentInfo, source_path: Path, output_dir: Path) -&gt; Path</code></li> <li><code>generate_folder_structure(document_info: DocumentInfo) -&gt; Path</code></li> <li><code>generate_filename(document_info: DocumentInfo) -&gt; str</code></li> <li><code>move_file(source: Path, destination: Path) -&gt; bool</code></li> <li><code>copy_file(source: Path, destination: Path) -&gt; bool</code></li> </ul>"},{"location":"api/#configuration-srcconfig","title":"Configuration (<code>src.config</code>)","text":"<p>The Configuration module provides centralized configuration management.</p>"},{"location":"api/#classes_3","title":"Classes","text":""},{"location":"api/#get_config-config","title":"<code>get_config() -&gt; Config</code>","text":"<p>Get the application configuration.</p> <pre><code>from src.config import get_config\n\nconfig = get_config()\nprint(config.organization.structure_pattern)\n</code></pre>"},{"location":"api/#config","title":"<code>Config</code>","text":"<p>Main configuration class.</p> <p>Attributes: - <code>organization: OrganizationConfig</code> - Organization settings - <code>ai: AIConfig</code> - AI provider settings - <code>processing: ProcessingConfig</code> - Processing settings - <code>web: WebConfig</code> - Web interface settings - <code>logging: LoggingConfig</code> - Logging settings</p>"},{"location":"api/#web-api","title":"Web API","text":""},{"location":"api/#endpoints","title":"Endpoints","text":""},{"location":"api/#post-apianalyze","title":"<code>POST /api/analyze</code>","text":"<p>Analyze a single PDF document.</p> <p>Request: <pre><code>{\n  \"file_path\": \"/path/to/document.pdf\",\n  \"provider\": \"openai\"\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"success\": true,\n  \"result\": {\n    \"company_name\": \"Chase Bank\",\n    \"document_type\": \"bank statement\",\n    \"date\": \"2023-05-15\",\n    \"confidence_score\": 0.95,\n    \"suggested_name\": \"Chase Bank Statement 2023-05-15\",\n    \"additional_metadata\": {\n      \"account_type\": \"checking\"\n    }\n  }\n}\n</code></pre></p>"},{"location":"api/#post-apiprocess","title":"<code>POST /api/process</code>","text":"<p>Process multiple PDF documents.</p> <p>Request: <pre><code>{\n  \"input_dir\": \"/path/to/input\",\n  \"output_dir\": \"/path/to/output\",\n  \"provider\": \"openai\",\n  \"dry_run\": false\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"success\": true,\n  \"results\": [\n    {\n      \"source_path\": \"/path/to/input/doc1.pdf\",\n      \"destination_path\": \"/path/to/output/Chase_Bank/2023/05/2023-05-15_Chase_Bank_Statement.pdf\",\n      \"document_info\": {\n        \"company_name\": \"Chase Bank\",\n        \"document_type\": \"bank statement\",\n        \"date\": \"2023-05-15\",\n        \"confidence_score\": 0.95,\n        \"suggested_name\": \"Chase Bank Statement 2023-05-15\"\n      }\n    }\n  ]\n}\n</code></pre></p>"},{"location":"api/#get-apistatus","title":"<code>GET /api/status</code>","text":"<p>Get system status.</p> <p>Response: <pre><code>{\n  \"status\": \"running\",\n  \"version\": \"1.0.0\",\n  \"ai_providers\": {\n    \"openai\": \"available\",\n    \"anthropic\": \"available\",\n    \"lm_studio\": \"unavailable\"\n  }\n}\n</code></pre></p>"},{"location":"api/#command-line-interface","title":"Command Line Interface","text":""},{"location":"api/#cli-module-clipy","title":"CLI Module (<code>cli.py</code>)","text":"<p>The CLI module provides command-line interface functionality.</p>"},{"location":"api/#functions","title":"Functions","text":""},{"location":"api/#main","title":"<code>main()</code>","text":"<p>Main CLI entry point.</p> <pre><code>from cli import main\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"api/#cli-options","title":"CLI Options","text":"<ul> <li><code>--input PATH</code> - Input directory</li> <li><code>--output PATH</code> - Output directory</li> <li><code>--dry-run</code> - Preview changes without moving files</li> <li><code>--copy</code> - Copy files instead of moving</li> <li><code>--confidence-threshold FLOAT</code> - Minimum confidence threshold</li> <li><code>--structure PATTERN</code> - Custom folder structure pattern</li> <li><code>--filename PATTERN</code> - Custom filename pattern</li> <li><code>--json-output PATH</code> - Save results to JSON file</li> <li><code>--verbose</code> - Enable verbose output</li> </ul>"},{"location":"api/#web-application","title":"Web Application","text":""},{"location":"api/#flask-app-apppy","title":"Flask App (<code>app.py</code>)","text":"<p>The Flask application provides a web interface for the system.</p>"},{"location":"api/#routes","title":"Routes","text":"<ul> <li><code>GET /</code> - Main interface</li> <li><code>POST /upload</code> - File upload</li> <li><code>POST /process</code> - Process uploaded files</li> <li><code>GET /status</code> - Processing status</li> <li><code>GET /download/&lt;filename&gt;</code> - Download processed files</li> </ul>"},{"location":"api/#templates","title":"Templates","text":"<ul> <li><code>templates/index.html</code> - Main interface template</li> </ul>"},{"location":"api/#error-handling","title":"Error Handling","text":""},{"location":"api/#exception-classes","title":"Exception Classes","text":""},{"location":"api/#aianalyzererror","title":"<code>AIAnalyzerError</code>","text":"<p>Raised when AI analysis fails.</p> <pre><code>from src.ai_analyzer import AIAnalyzerError\n\ntry:\n    result = analyzer.analyze_document(document)\nexcept AIAnalyzerError as e:\n    print(f\"AI analysis failed: {e}\")\n</code></pre>"},{"location":"api/#pdfprocessingerror","title":"<code>PDFProcessingError</code>","text":"<p>Raised when PDF processing fails.</p> <pre><code>from src.pdf_processor import PDFProcessingError\n\ntry:\n    doc = processor.process_pdf(file_path)\nexcept PDFProcessingError as e:\n    print(f\"PDF processing failed: {e}\")\n</code></pre>"},{"location":"api/#fileorganizationerror","title":"<code>FileOrganizationError</code>","text":"<p>Raised when file organization fails.</p> <pre><code>from src.file_organizer import FileOrganizationError\n\ntry:\n    organizer.organize_file(document_info, source_path, output_dir)\nexcept FileOrganizationError as e:\n    print(f\"File organization failed: {e}\")\n</code></pre>"},{"location":"api/#logging","title":"Logging","text":""},{"location":"api/#logger-configuration","title":"Logger Configuration","text":"<pre><code>import logging\nfrom src.config import get_config\n\nconfig = get_config()\nlogging.basicConfig(\n    level=getattr(logging, config.logging.level),\n    format=config.logging.format,\n    handlers=[\n        logging.FileHandler(config.logging.file),\n        logging.StreamHandler()\n    ]\n)\n</code></pre>"},{"location":"api/#log-levels","title":"Log Levels","text":"<ul> <li><code>DEBUG</code> - Detailed information for debugging</li> <li><code>INFO</code> - General information about program execution</li> <li><code>WARNING</code> - Warning messages for potential issues</li> <li><code>ERROR</code> - Error messages for failed operations</li> <li><code>CRITICAL</code> - Critical errors that may cause program termination</li> </ul>"},{"location":"api/#testing","title":"Testing","text":""},{"location":"api/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 test_ai_analyzer.py      # AI analyzer tests\n\u251c\u2500\u2500 test_pdf_processor.py     # PDF processor tests\n\u251c\u2500\u2500 test_file_organizer.py    # File organizer tests\n\u251c\u2500\u2500 test_config.py           # Configuration tests\n\u251c\u2500\u2500 test_e2e_integration.py  # End-to-end tests\n\u2514\u2500\u2500 conftest.py              # Test fixtures\n</code></pre>"},{"location":"api/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npytest\n\n# Run specific test module\npytest tests/test_ai_analyzer.py\n\n# Run with coverage\npytest --cov=src --cov-report=html\n\n# Run specific test\npytest tests/test_ai_analyzer.py::TestAIAnalyzer::test_analyze_document\n</code></pre>"},{"location":"api/#test-fixtures","title":"Test Fixtures","text":"<pre><code>import pytest\nfrom src.ai_analyzer import AIAnalyzer\n\n@pytest.fixture\ndef analyzer():\n    return AIAnalyzer(provider='openai')\n\n@pytest.fixture\ndef sample_document():\n    from src.pdf_processor import PDFDocument\n    from pathlib import Path\n\n    return PDFDocument(\n        file_path=Path(\"test.pdf\"),\n        text_content=\"Sample content\",\n        metadata={},\n        page_count=1,\n        extraction_method=\"pypdf\"\n    )\n</code></pre>"},{"location":"api/#performance-considerations","title":"Performance Considerations","text":""},{"location":"api/#memory-usage","title":"Memory Usage","text":"<ul> <li>PDF processing can be memory-intensive for large files</li> <li>Use batch processing for large document sets</li> <li>Consider file size limits in configuration</li> </ul>"},{"location":"api/#processing-speed","title":"Processing Speed","text":"<ul> <li>AI analysis is the bottleneck in most cases</li> <li>Local models (LM Studio) are slower than cloud APIs</li> <li>Batch processing can improve throughput</li> </ul>"},{"location":"api/#optimization-tips","title":"Optimization Tips","text":"<ol> <li>Use appropriate batch sizes based on system resources</li> <li>Configure timeouts to prevent hanging requests</li> <li>Use efficient folder structures for your use case</li> <li>Monitor memory usage during processing</li> <li>Consider parallel processing for large batches</li> </ol>"},{"location":"api/#security-considerations","title":"Security Considerations","text":""},{"location":"api/#api-key-management","title":"API Key Management","text":"<ul> <li>Store API keys in environment variables</li> <li>Never commit API keys to version control</li> <li>Use different keys for different environments</li> <li>Regularly rotate API keys</li> </ul>"},{"location":"api/#file-security","title":"File Security","text":"<ul> <li>Validate file types before processing</li> <li>Check file sizes to prevent DoS attacks</li> <li>Sanitize filenames to prevent path traversal</li> <li>Use secure file permissions</li> </ul>"},{"location":"api/#network-security","title":"Network Security","text":"<ul> <li>Use HTTPS for cloud AI providers</li> <li>Validate SSL certificates</li> <li>Use secure communication protocols</li> <li>Implement rate limiting for API calls</li> </ul>"},{"location":"api/#integration-examples","title":"Integration Examples","text":""},{"location":"api/#custom-processing-pipeline","title":"Custom Processing Pipeline","text":"<pre><code>from src.pdf_processor import PDFProcessor\nfrom src.ai_analyzer import AIAnalyzer\nfrom src.file_organizer import FileOrganizer\n\ndef custom_process_pdf(file_path, output_dir):\n    # Process PDF\n    processor = PDFProcessor()\n    document = processor.process_pdf(file_path)\n\n    # Analyze document\n    analyzer = AIAnalyzer(provider='openai')\n    document_info = analyzer.analyze_document(document)\n\n    # Organize file\n    organizer = FileOrganizer()\n    destination = organizer.organize_file(\n        document_info, file_path, output_dir\n    )\n\n    return destination\n</code></pre>"},{"location":"api/#batch-processing","title":"Batch Processing","text":"<pre><code>from pathlib import Path\nfrom src.config import get_config\n\ndef batch_process(input_dir, output_dir):\n    config = get_config()\n    processor = PDFProcessor()\n    analyzer = AIAnalyzer(provider=config.ai.preferred_provider)\n    organizer = FileOrganizer()\n\n    results = []\n    for pdf_file in Path(input_dir).glob(\"*.pdf\"):\n        try:\n            # Process document\n            document = processor.process_pdf(pdf_file)\n            document_info = analyzer.analyze_document(document)\n            destination = organizer.organize_file(\n                document_info, pdf_file, output_dir\n            )\n            results.append({\n                'source': pdf_file,\n                'destination': destination,\n                'info': document_info\n            })\n        except Exception as e:\n            print(f\"Failed to process {pdf_file}: {e}\")\n\n    return results\n</code></pre>"},{"location":"api/#webhook-integration","title":"Webhook Integration","text":"<pre><code>from flask import Flask, request, jsonify\nfrom src.pdf_processor import PDFProcessor\nfrom src.ai_analyzer import AIAnalyzer\n\napp = Flask(__name__)\n\n@app.route('/webhook/process', methods=['POST'])\ndef webhook_process():\n    data = request.json\n    file_path = data.get('file_path')\n\n    if not file_path:\n        return jsonify({'error': 'file_path required'}), 400\n\n    try:\n        # Process document\n        processor = PDFProcessor()\n        document = processor.process_pdf(Path(file_path))\n\n        analyzer = AIAnalyzer(provider='openai')\n        document_info = analyzer.analyze_document(document)\n\n        return jsonify({\n            'success': True,\n            'result': document_info.__dict__\n        })\n    except Exception as e:\n        return jsonify({'error': str(e)}), 500\n</code></pre>"},{"location":"api/#troubleshooting","title":"Troubleshooting","text":""},{"location":"api/#common-issues","title":"Common Issues","text":"<ol> <li>Import errors: Ensure all dependencies are installed</li> <li>Configuration errors: Check YAML syntax and file permissions</li> <li>AI provider errors: Verify API keys and network connectivity</li> <li>File processing errors: Check file permissions and formats</li> <li>Memory errors: Reduce batch sizes or file sizes</li> </ol>"},{"location":"api/#debug-mode","title":"Debug Mode","text":"<pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n\n# Enable debug mode in configuration\nconfig = get_config()\nconfig.logging.level = \"DEBUG\"\n</code></pre>"},{"location":"api/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code>import time\nfrom src.config import get_config\n\ndef monitor_performance(func):\n    def wrapper(*args, **kwargs):\n        start_time = time.time()\n        result = func(*args, **kwargs)\n        end_time = time.time()\n\n        print(f\"{func.__name__} took {end_time - start_time:.2f} seconds\")\n        return result\n    return wrapper\n\n@monitor_performance\ndef process_document(file_path):\n    # Document processing code\n    pass\n</code></pre>"},{"location":"cli-usage/","title":"OCRganizer CLI Usage","text":""},{"location":"cli-usage/#quick-start","title":"Quick Start","text":"<p>Your <code>.env</code> file is already configured with: - \u2705 OpenAI API key (or can be configured for LM Studio) - \u2705 Input directory: <code>/Users/jeff/Downloads/PDFs</code> - \u2705 Output directory: <code>smb://BigNas._smb._tcp.local/Games/TempDocSpot</code></p>"},{"location":"cli-usage/#ai-provider-options","title":"AI Provider Options","text":""},{"location":"cli-usage/#using-openai-cloud-current-setup","title":"Using OpenAI (Cloud) - Current Setup","text":"<p>Your current configuration uses OpenAI's cloud API.</p>"},{"location":"cli-usage/#using-lm-studio-localprivate","title":"Using LM Studio (Local/Private)","text":"<p>To switch to local LM Studio for privacy and offline processing:</p> <pre><code># Edit your .env file:\nOPENAI_BASE_URL=http://localhost:1234/v1\nOPENAI_API_KEY=lm-studio\nLOCAL_MODEL_NAME=your-loaded-model-name\n</code></pre> <p>\ud83d\udcd6 See LM_STUDIO_SETUP.md for detailed setup instructions</p>"},{"location":"cli-usage/#simple-commands","title":"Simple Commands","text":""},{"location":"cli-usage/#1-preview-mode-recommended-first","title":"1. Preview Mode (Recommended First)","text":"<p>See what would be organized without moving files: <pre><code>./preview_pdfs.sh\n</code></pre></p>"},{"location":"cli-usage/#2-process-all-pdfs","title":"2. Process All PDFs","text":"<p>Organize all PDFs from your input to output directory: <pre><code>./process_pdfs.sh\n</code></pre></p>"},{"location":"cli-usage/#3-direct-cli-usage","title":"3. Direct CLI Usage","text":"<pre><code># Preview what would be organized\npython cli.py --dry-run\n\n# Actually organize the files\npython cli.py\n\n# Copy files instead of moving them\npython cli.py --copy\n\n# Use Anthropic instead of OpenAI\npython cli.py --provider anthropic\n\n# Show detailed progress\npython cli.py --verbose\n</code></pre>"},{"location":"cli-usage/#advanced-options","title":"Advanced Options","text":""},{"location":"cli-usage/#custom-directories","title":"Custom Directories","text":"<pre><code>python cli.py --input /path/to/your/pdfs --output /path/to/organized\n</code></pre>"},{"location":"cli-usage/#custom-organization-structure","title":"Custom Organization Structure","text":"<pre><code># Different folder structure\npython cli.py --structure \"{year}/{company}/{type}\"\n\n# Different filename pattern\npython cli.py --filename \"{date}_{company}_{type}\"\n</code></pre>"},{"location":"cli-usage/#save-results","title":"Save Results","text":"<pre><code># Save processing results to JSON\npython cli.py --json-output results.json\n</code></pre>"},{"location":"cli-usage/#confidence-threshold","title":"Confidence Threshold","text":"<pre><code># Only process files with high confidence (0.8+)\npython cli.py --confidence-threshold 0.8\n</code></pre>"},{"location":"cli-usage/#examples","title":"Examples","text":""},{"location":"cli-usage/#basic-processing","title":"Basic Processing","text":"<pre><code># Process all PDFs using your .env settings\npython cli.py\n</code></pre>"},{"location":"cli-usage/#preview-before-processing","title":"Preview Before Processing","text":"<pre><code># See what would happen\npython cli.py --dry-run --verbose\n\n# Then actually do it\npython cli.py --verbose\n</code></pre>"},{"location":"cli-usage/#custom-settings","title":"Custom Settings","text":"<pre><code># Use different AI provider with custom structure\npython cli.py \\\n  --provider anthropic \\\n  --structure \"{company}/{type}/{year}\" \\\n  --filename \"{company}_{type}_{date}\" \\\n  --verbose\n</code></pre>"},{"location":"cli-usage/#output-structure","title":"Output Structure","text":"<p>Files will be organized as: <pre><code>output/\n\u251c\u2500\u2500 Chase Bank/\n\u2502   \u2514\u2500\u2500 2023/\n\u2502       \u2514\u2500\u2500 03/\n\u2502           \u2514\u2500\u2500 15/\n\u2502               \u2514\u2500\u2500 Chase_Bank_statement_2023-03-15.pdf\n\u251c\u2500\u2500 Verizon/\n\u2502   \u2514\u2500\u2500 2023/\n\u2502       \u2514\u2500\u2500 04/\n\u2502           \u2514\u2500\u2500 01/\n\u2502               \u2514\u2500\u2500 Verizon_phone_bill_2023-04-01.pdf\n\u2514\u2500\u2500 ...\n</code></pre></p>"},{"location":"cli-usage/#troubleshooting","title":"Troubleshooting","text":""},{"location":"cli-usage/#no-pdfs-found","title":"No PDFs Found","text":"<pre><code># Check if input directory has PDFs\nls /Users/jeff/Downloads/PDFs/*.pdf\n</code></pre>"},{"location":"cli-usage/#api-key-issues","title":"API Key Issues","text":"<pre><code># Check your .env file\ncat .env | grep API_KEY\n</code></pre>"},{"location":"cli-usage/#permission-issues","title":"Permission Issues","text":"<pre><code># Make sure scripts are executable\nchmod +x *.sh\n</code></pre>"},{"location":"cli-usage/#results","title":"Results","text":"<p>After processing, you'll get: - \u2705 Organized files in your output directory - \ud83d\udcca <code>processing_results.json</code> with detailed results - \ud83d\udcc8 Summary of companies and document types found</p>"},{"location":"cli-usage/#next-steps","title":"Next Steps","text":"<ol> <li>Add PDFs to <code>/Users/jeff/Downloads/PDFs/</code></li> <li>Preview with <code>./preview_pdfs.sh</code></li> <li>Process with <code>./process_pdfs.sh</code></li> <li>Check results in your output directory!</li> </ol> <p>Happy organizing! \ud83c\udf89</p>"},{"location":"configuration/","title":"Configuration Reference","text":"<p>This document provides detailed information about configuring the OCRganizer system.</p>"},{"location":"configuration/#configuration-files","title":"Configuration Files","text":"<p>The system uses multiple configuration files:</p> <ol> <li><code>env</code> - Environment variables and secrets</li> <li><code>config.yaml</code> - Application settings</li> <li><code>pyproject.toml</code> - Package configuration</li> </ol>"},{"location":"configuration/#environment-variables-env","title":"Environment Variables (<code>env</code>)","text":"<p>\ud83d\udcd6 For detailed AI provider setup instructions, see AI Provider Setup</p>"},{"location":"configuration/#optional-environment-variables","title":"Optional Environment Variables","text":"<pre><code># Logging level\nLOG_LEVEL=INFO\n\n# Default input/output directories\nDEFAULT_INPUT_DIR=input_pdfs\nDEFAULT_OUTPUT_DIR=output\n\n# AI provider selection\nPREFERRED_AI_PROVIDER=openai\n</code></pre>"},{"location":"configuration/#application-configuration-configyaml","title":"Application Configuration (<code>config.yaml</code>)","text":""},{"location":"configuration/#organization-settings","title":"Organization Settings","text":"<pre><code>organization:\n  # Folder structure pattern\n  structure_pattern: \"{company}/{year}/{month}\"\n\n  # Filename pattern\n  filename_pattern: \"{date}_{company}_{type}\"\n\n  # Minimum confidence for auto-processing\n  confidence_threshold: 0.7\n\n  # Create year-only folders for incomplete dates\n  create_year_folders: true\n\n  # Create month-only folders for incomplete dates\n  create_month_folders: true\n</code></pre>"},{"location":"configuration/#ai-settings","title":"AI Settings","text":"<pre><code>ai:\n  # Preferred AI provider (openai, anthropic, lm_studio)\n  preferred_provider: \"openai\"\n\n  # Maximum tokens for AI analysis\n  max_tokens: 800\n\n  # Temperature for AI responses (0.0-1.0)\n  temperature: 0.1\n\n  # Retry attempts for failed AI calls\n  retry_attempts: 3\n\n  # Timeout for AI requests (seconds)\n  timeout_seconds: 30\n</code></pre>"},{"location":"configuration/#processing-settings","title":"Processing Settings","text":"<pre><code>processing:\n  # Number of files to process in each batch\n  batch_size: 10\n\n  # Maximum file size (MB)\n  max_file_size: 50\n\n  # Enable OCR for scanned documents\n  enable_ocr: true\n\n  # OCR language (ISO 639-1 code)\n  ocr_language: \"eng\"\n\n  # Text extraction methods to try\n  extraction_methods:\n    - \"pypdf\"\n    - \"pdfplumber\"\n    - \"ocr\"\n</code></pre>"},{"location":"configuration/#web-interface-settings","title":"Web Interface Settings","text":"<pre><code>web:\n  # Host for web interface\n  host: \"0.0.0.0\"\n\n  # Port for web interface\n  port: 5000\n\n  # Enable debug mode\n  debug: false\n\n  # Maximum file upload size (MB)\n  max_upload_size: 100\n\n  # Allowed file extensions\n  allowed_extensions: [\".pdf\"]\n</code></pre>"},{"location":"configuration/#logging-settings","title":"Logging Settings","text":"<pre><code>logging:\n  # Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n  level: \"INFO\"\n\n  # Log file path\n  file: \"logs/app.log\"\n\n  # Maximum log file size (MB)\n  max_size: 10\n\n  # Number of backup log files\n  backup_count: 5\n\n  # Log format\n  format: \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n</code></pre>"},{"location":"configuration/#pattern-variables","title":"Pattern Variables","text":""},{"location":"configuration/#folder-structure-patterns","title":"Folder Structure Patterns","text":"<p>Available variables for <code>structure_pattern</code>:</p> <ul> <li><code>{company}</code> - Company/organization name</li> <li><code>{year}</code> - Document year</li> <li><code>{month}</code> - Document month (01-12)</li> <li><code>{day}</code> - Document day (01-31)</li> <li><code>{type}</code> - Document type</li> <li><code>{date}</code> - Full date (YYYY-MM-DD)</li> </ul> <p>Examples: <pre><code># Default: Company/Year/Month\nstructure_pattern: \"{company}/{year}/{month}\"\n\n# By document type: Company/Type/Year\nstructure_pattern: \"{company}/{type}/{year}\"\n\n# Year-first: Year/Company/Month\nstructure_pattern: \"{year}/{company}/{month}\"\n\n# Flat structure: All files in one folder\nstructure_pattern: \"\"\n</code></pre></p>"},{"location":"configuration/#filename-patterns","title":"Filename Patterns","text":"<p>Available variables for <code>filename_pattern</code>:</p> <ul> <li><code>{date}</code> - Full date (YYYY-MM-DD)</li> <li><code>{year}</code> - Year (YYYY)</li> <li><code>{month}</code> - Month (MM)</li> <li><code>{day}</code> - Day (DD)</li> <li><code>{company}</code> - Company name</li> <li><code>{type}</code> - Document type</li> <li><code>{original}</code> - Original filename (without extension)</li> </ul> <p>Examples: <pre><code># Default: Date_Company_Type\nfilename_pattern: \"{date}_{company}_{type}\"\n\n# Company-first: Company_Type_Date\nfilename_pattern: \"{company}_{type}_{date}\"\n\n# Detailed: Year_Month_Day_Company_Type\nfilename_pattern: \"{year}_{month}_{day}_{company}_{type}\"\n\n# Simple: Company_Type\nfilename_pattern: \"{company}_{type}\"\n</code></pre></p>"},{"location":"configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"configuration/#custom-ai-prompts","title":"Custom AI Prompts","text":"<p>You can customize the AI prompts used for document analysis:</p> <pre><code>ai:\n  prompts:\n    openai:\n      system: \"You are a document analysis expert...\"\n      user: \"Analyze this document and extract...\"\n\n    anthropic:\n      system: \"You are a document analysis expert...\"\n      user: \"Analyze this document and extract...\"\n</code></pre>"},{"location":"configuration/#file-processing-rules","title":"File Processing Rules","text":"<pre><code>processing:\n  rules:\n    # Skip files smaller than this (bytes)\n    min_file_size: 1024\n\n    # Skip files larger than this (bytes)\n    max_file_size: 52428800\n\n    # File patterns to skip\n    skip_patterns:\n      - \"*.tmp\"\n      - \"*.temp\"\n      - \".*\"\n\n    # File patterns to include\n    include_patterns:\n      - \"*.pdf\"\n</code></pre>"},{"location":"configuration/#error-handling","title":"Error Handling","text":"<pre><code>error_handling:\n  # Continue processing on individual file errors\n  continue_on_error: true\n\n  # Maximum consecutive errors before stopping\n  max_consecutive_errors: 5\n\n  # Retry failed files\n  retry_failed: true\n\n  # Log all errors to file\n  log_errors: true\n</code></pre>"},{"location":"configuration/#configuration-validation","title":"Configuration Validation","text":"<p>The system validates configuration on startup:</p>"},{"location":"configuration/#required-settings","title":"Required Settings","text":"<ul> <li>AI provider API key</li> <li>Valid folder structure pattern</li> <li>Valid filename pattern</li> </ul>"},{"location":"configuration/#optional-settings","title":"Optional Settings","text":"<ul> <li>Logging configuration</li> <li>Processing limits</li> <li>Web interface settings</li> </ul>"},{"location":"configuration/#validation-errors","title":"Validation Errors","text":"<p>Common validation errors and solutions:</p> <p>\"Invalid structure pattern\" - Check for valid variable names - Ensure proper syntax</p> <p>\"Invalid filename pattern\" - Check for valid variable names - Avoid invalid filename characters</p> <p>\"Missing API key\" - Ensure API key is set in <code>env</code> file - Check for typos in variable names</p>"},{"location":"configuration/#environment-specific-configuration","title":"Environment-Specific Configuration","text":""},{"location":"configuration/#development-environment","title":"Development Environment","text":"<pre><code># config.dev.yaml\nlogging:\n  level: \"DEBUG\"\n\nweb:\n  debug: true\n\nprocessing:\n  batch_size: 1\n</code></pre>"},{"location":"configuration/#production-environment","title":"Production Environment","text":"<pre><code># config.prod.yaml\nlogging:\n  level: \"INFO\"\n\nweb:\n  debug: false\n\nprocessing:\n  batch_size: 20\n</code></pre>"},{"location":"configuration/#testing-environment","title":"Testing Environment","text":"<pre><code># config.test.yaml\nai:\n  preferred_provider: \"mock\"\n\nprocessing:\n  batch_size: 1\n  enable_ocr: false\n</code></pre>"},{"location":"configuration/#configuration-overrides","title":"Configuration Overrides","text":""},{"location":"configuration/#command-line-overrides","title":"Command Line Overrides","text":"<pre><code># Override confidence threshold\npython cli.py --confidence-threshold 0.8\n\n# Override folder structure\npython cli.py --structure \"{company}/{type}\"\n\n# Override filename pattern\npython cli.py --filename \"{company}_{type}_{date}\"\n</code></pre>"},{"location":"configuration/#environment-variable-overrides","title":"Environment Variable Overrides","text":"<pre><code># Override AI provider\nexport PREFERRED_AI_PROVIDER=anthropic\n\n# Override confidence threshold\nexport CONFIDENCE_THRESHOLD=0.8\n\n# Override batch size\nexport BATCH_SIZE=5\n</code></pre>"},{"location":"configuration/#configuration-examples","title":"Configuration Examples","text":""},{"location":"configuration/#basic-setup","title":"Basic Setup","text":"<pre><code># config.yaml\norganization:\n  structure_pattern: \"{company}/{year}/{month}\"\n  filename_pattern: \"{date}_{company}_{type}\"\n  confidence_threshold: 0.7\n\nai:\n  preferred_provider: \"openai\"\n  max_tokens: 800\n  temperature: 0.1\n\nprocessing:\n  batch_size: 10\n  enable_ocr: true\n</code></pre>"},{"location":"configuration/#advanced-setup","title":"Advanced Setup","text":"<pre><code># config.yaml\norganization:\n  structure_pattern: \"{company}/{type}/{year}\"\n  filename_pattern: \"{year}_{month}_{day}_{company}_{type}\"\n  confidence_threshold: 0.8\n  create_year_folders: true\n  create_month_folders: true\n\nai:\n  preferred_provider: \"anthropic\"\n  max_tokens: 1200\n  temperature: 0.2\n  retry_attempts: 5\n  timeout_seconds: 60\n\nprocessing:\n  batch_size: 20\n  max_file_size: 100\n  enable_ocr: true\n  ocr_language: \"eng\"\n  extraction_methods: [\"pypdf\", \"pdfplumber\", \"ocr\"]\n\nweb:\n  host: \"0.0.0.0\"\n  port: 5000\n  debug: false\n  max_upload_size: 200\n\nlogging:\n  level: \"INFO\"\n  file: \"logs/app.log\"\n  max_size: 20\n  backup_count: 10\n</code></pre>"},{"location":"configuration/#troubleshooting-configuration","title":"Troubleshooting Configuration","text":""},{"location":"configuration/#common-issues","title":"Common Issues","text":"<p>1. Configuration not loading: - Check file syntax (YAML format) - Verify file permissions - Check for typos in variable names</p> <p>2. Environment variables not working: - Ensure <code>env</code> file exists - Check variable names match exactly - Restart the application after changes</p> <p>3. Pattern validation errors: - Use valid variable names in patterns - Check for special characters - Test patterns with sample data</p>"},{"location":"configuration/#configuration-testing","title":"Configuration Testing","text":"<pre><code># Test configuration loading\npython -c \"from src.config import get_config; print(get_config())\"\n\n# Test specific settings\npython -c \"from src.config import get_config; config = get_config(); print(config.organization.structure_pattern)\"\n</code></pre>"},{"location":"configuration/#best-practices","title":"Best Practices","text":""},{"location":"configuration/#configuration-management","title":"Configuration Management","text":"<ol> <li>Use version control for configuration files</li> <li>Keep secrets in environment variables</li> <li>Use different configs for different environments</li> <li>Document custom configurations</li> <li>Test configurations before deployment</li> </ol>"},{"location":"configuration/#security-considerations","title":"Security Considerations","text":"<ol> <li>Never commit API keys to version control</li> <li>Use environment variables for sensitive data</li> <li>Restrict file permissions on config files</li> <li>Use secure communication for remote configurations</li> <li>Regularly rotate API keys</li> </ol>"},{"location":"configuration/#performance-optimization","title":"Performance Optimization","text":"<ol> <li>Adjust batch sizes based on system resources</li> <li>Configure appropriate timeouts for AI providers</li> <li>Use efficient folder structures for your use case</li> <li>Monitor and adjust based on performance metrics</li> <li>Cache frequently used configurations</li> </ol>"},{"location":"developer-guide/","title":"Developer Guide","text":"<p>This comprehensive guide will help developers understand, set up, and contribute to the OCRganizer project.</p>"},{"location":"developer-guide/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Quick Start</li> <li>Development Environment</li> <li>Project Structure</li> <li>Code Architecture</li> <li>Testing</li> <li>Contributing</li> <li>Debugging</li> <li>Performance Optimization</li> </ul>"},{"location":"developer-guide/#quick-start","title":"Quick Start","text":"<p>\ud83d\udcd6 For a quick 5-minute setup, see Quick Start Guide</p>"},{"location":"developer-guide/#development-environment","title":"Development Environment","text":""},{"location":"developer-guide/#recommended-ide-setup","title":"Recommended IDE Setup","text":""},{"location":"developer-guide/#vs-code-recommended","title":"VS Code (Recommended)","text":"<ol> <li>Install VS Code: https://code.visualstudio.com</li> <li>Install Python Extension: Search for \"Python\" in extensions</li> <li>Install Recommended Extensions:    <pre><code>{\n  \"recommendations\": [\n    \"ms-python.python\",\n    \"ms-python.black-formatter\",\n    \"ms-python.isort\",\n    \"ms-python.flake8\",\n    \"ms-python.mypy\",\n    \"ms-toolsai.jupyter\"\n  ]\n}\n</code></pre></li> </ol>"},{"location":"developer-guide/#pycharm","title":"PyCharm","text":"<ol> <li>Install PyCharm: https://www.jetbrains.com/pycharm</li> <li>Open Project: Open the project directory</li> <li>Configure Interpreter: Set Python interpreter to your virtual environment</li> <li>Install Plugins: Black, isort, flake8, mypy</li> </ol>"},{"location":"developer-guide/#development-tools","title":"Development Tools","text":""},{"location":"developer-guide/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<pre><code># Install pre-commit\npip install pre-commit\n\n# Install hooks\npre-commit install\n\n# Run hooks manually\npre-commit run --all-files\n</code></pre>"},{"location":"developer-guide/#code-formatting","title":"Code Formatting","text":"<pre><code># Format code with black\nblack src tests\n\n# Sort imports with isort\nisort src tests\n\n# Lint with flake8\nflake8 src tests\n\n# Type check with mypy\nmypy src\n</code></pre>"},{"location":"developer-guide/#environment-variables","title":"Environment Variables","text":"<p>Create a <code>.env</code> file for development:</p> <pre><code># AI Provider (choose one)\nOPENAI_API_KEY=your_openai_key_here\n# ANTHROPIC_API_KEY=your_anthropic_key_here\n\n# Development settings\nDEBUG=True\nLOG_LEVEL=DEBUG\n\n# Test settings\nTEST_MODE=True\nMOCK_AI_PROVIDERS=True\n</code></pre>"},{"location":"developer-guide/#project-structure","title":"Project Structure","text":"<pre><code>OCRganizer/\n\u251c\u2500\u2500 src/                          # Core application code\n\u2502   \u251c\u2500\u2500 __init__.py               # Package initialization\n\u2502   \u251c\u2500\u2500 ai_analyzer.py            # AI analysis logic\n\u2502   \u251c\u2500\u2500 pdf_processor.py          # PDF text extraction\n\u2502   \u251c\u2500\u2500 file_organizer.py         # File organization logic\n\u2502   \u251c\u2500\u2500 config.py                 # Configuration management\n\u2502   \u2514\u2500\u2500 lm_studio_client.py       # Local AI integration\n\u251c\u2500\u2500 tests/                        # Test suite\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 conftest.py               # Test fixtures\n\u2502   \u251c\u2500\u2500 test_ai_analyzer.py       # AI analyzer tests\n\u2502   \u251c\u2500\u2500 test_pdf_processor.py     # PDF processor tests\n\u2502   \u251c\u2500\u2500 test_file_organizer.py    # File organizer tests\n\u2502   \u251c\u2500\u2500 test_config.py            # Configuration tests\n\u2502   \u2514\u2500\u2500 test_e2e_integration.py   # End-to-end tests\n\u251c\u2500\u2500 docs/                         # Documentation\n\u251c\u2500\u2500 scripts/                      # Utility scripts\n\u2502   \u251c\u2500\u2500 version.py                # Version management\n\u2502   \u2514\u2500\u2500 test-ci.sh               # CI testing script\n\u251c\u2500\u2500 .github/                      # GitHub workflows\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u251c\u2500\u2500 ci.yml                # CI/CD pipeline\n\u2502       \u2514\u2500\u2500 docs.yml              # Documentation deployment\n\u251c\u2500\u2500 templates/                    # Web interface templates\n\u251c\u2500\u2500 input_pdfs/                   # Sample input files\n\u251c\u2500\u2500 output/                       # Processed files\n\u251c\u2500\u2500 logs/                         # Log files\n\u251c\u2500\u2500 app.py                        # Web application entry point\n\u251c\u2500\u2500 cli.py                        # Command-line interface\n\u251c\u2500\u2500 config.yaml                   # Application configuration\n\u251c\u2500\u2500 pyproject.toml                # Package configuration\n\u251c\u2500\u2500 requirements.txt              # Python dependencies\n\u251c\u2500\u2500 Dockerfile                    # Container configuration\n\u251c\u2500\u2500 .pre-commit-config.yaml       # Pre-commit hooks\n\u251c\u2500\u2500 .flake8                       # Flake8 configuration\n\u2514\u2500\u2500 README.md                     # Project documentation\n</code></pre>"},{"location":"developer-guide/#code-architecture","title":"Code Architecture","text":""},{"location":"developer-guide/#core-modules","title":"Core Modules","text":""},{"location":"developer-guide/#ai-analyzer-srcai_analyzerpy","title":"AI Analyzer (<code>src/ai_analyzer.py</code>)","text":"<p>Purpose: Handles AI-powered document analysis</p> <p>Key Classes: - <code>AIAnalyzer</code>: Main analyzer class - <code>DocumentInfo</code>: Data class for analysis results - <code>AIProvider</code>: Protocol for AI providers</p> <p>Key Methods: - <code>analyze_document()</code>: Analyze a PDF document - <code>get_provider_info()</code>: Get provider information</p> <p>Example Usage: <pre><code>from src.ai_analyzer import AIAnalyzer, DocumentInfo\n\n# Initialize analyzer\nanalyzer = AIAnalyzer(provider='openai')\n\n# Analyze document\ndocument_info = analyzer.analyze_document(pdf_document)\nprint(f\"Company: {document_info.company_name}\")\nprint(f\"Type: {document_info.document_type}\")\n</code></pre></p>"},{"location":"developer-guide/#pdf-processor-srcpdf_processorpy","title":"PDF Processor (<code>src/pdf_processor.py</code>)","text":"<p>Purpose: Extracts text from PDF documents</p> <p>Key Classes: - <code>PDFProcessor</code>: Main processor class - <code>PDFDocument</code>: Data class for processed PDFs</p> <p>Key Methods: - <code>process_pdf()</code>: Process a PDF file - <code>extract_text_pypdf()</code>: Extract text using pypdf - <code>extract_text_ocr()</code>: Extract text using OCR</p> <p>Example Usage: <pre><code>from src.pdf_processor import PDFProcessor\nfrom pathlib import Path\n\n# Initialize processor\nprocessor = PDFProcessor()\n\n# Process PDF\npdf_doc = processor.process_pdf(Path(\"document.pdf\"))\nprint(f\"Text: {pdf_doc.text_content}\")\nprint(f\"Pages: {pdf_doc.page_count}\")\n</code></pre></p>"},{"location":"developer-guide/#file-organizer-srcfile_organizerpy","title":"File Organizer (<code>src/file_organizer.py</code>)","text":"<p>Purpose: Organizes files based on analysis results</p> <p>Key Classes: - <code>FileOrganizer</code>: Main organizer class</p> <p>Key Methods: - <code>organize_file()</code>: Organize a single file - <code>generate_folder_structure()</code>: Generate folder structure - <code>generate_filename()</code>: Generate filename</p> <p>Example Usage: <pre><code>from src.file_organizer import FileOrganizer\nfrom src.ai_analyzer import DocumentInfo\n\n# Initialize organizer\norganizer = FileOrganizer()\n\n# Organize file\ndestination = organizer.organize_file(\n    document_info, \n    source_path, \n    output_dir\n)\nprint(f\"File moved to: {destination}\")\n</code></pre></p>"},{"location":"developer-guide/#configuration-srcconfigpy","title":"Configuration (<code>src/config.py</code>)","text":"<p>Purpose: Manages application configuration</p> <p>Key Classes: - <code>Config</code>: Main configuration class - <code>OrganizationConfig</code>: Organization settings - <code>AIConfig</code>: AI provider settings</p> <p>Example Usage: <pre><code>from src.config import get_config\n\n# Get configuration\nconfig = get_config()\n\n# Access settings\nprint(f\"Structure pattern: {config.organization.structure_pattern}\")\nprint(f\"AI provider: {config.ai.preferred_provider}\")\n</code></pre></p>"},{"location":"developer-guide/#design-patterns","title":"Design Patterns","text":""},{"location":"developer-guide/#protocol-based-design","title":"Protocol-Based Design","text":"<p>The system uses Python protocols for AI providers:</p> <pre><code>class AIProvider(Protocol):\n    def analyze_document_text(self, text: str, max_tokens: int = 800) -&gt; str:\n        \"\"\"Analyze document text and return JSON response.\"\"\"\n        ...\n</code></pre>"},{"location":"developer-guide/#dependency-injection","title":"Dependency Injection","text":"<p>AI providers are injected into the analyzer:</p> <pre><code>class AIAnalyzer:\n    def __init__(self, provider: str):\n        self.provider = provider\n        self.client = self._create_client()\n</code></pre>"},{"location":"developer-guide/#error-handling","title":"Error Handling","text":"<p>Comprehensive error handling with fallbacks:</p> <pre><code>try:\n    result = analyzer.analyze_document(document)\nexcept AIAnalyzerError as e:\n    logger.error(f\"AI analysis failed: {e}\")\n    result = create_fallback_document_info(document)\n</code></pre>"},{"location":"developer-guide/#testing","title":"Testing","text":""},{"location":"developer-guide/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 conftest.py                   # Shared fixtures\n\u251c\u2500\u2500 test_ai_analyzer.py           # AI analyzer tests\n\u251c\u2500\u2500 test_pdf_processor.py         # PDF processor tests\n\u251c\u2500\u2500 test_file_organizer.py        # File organizer tests\n\u251c\u2500\u2500 test_config.py                # Configuration tests\n\u2514\u2500\u2500 test_e2e_integration.py       # End-to-end tests\n</code></pre>"},{"location":"developer-guide/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npytest\n\n# Run with coverage\npytest --cov=src --cov-report=html\n\n# Run specific test\npytest tests/test_ai_analyzer.py::TestAIAnalyzer::test_analyze_document\n\n# Run with verbose output\npytest -v\n\n# Run only fast tests\npytest -m \"not slow\"\n</code></pre>"},{"location":"developer-guide/#test-categories","title":"Test Categories","text":""},{"location":"developer-guide/#unit-tests","title":"Unit Tests","text":"<ul> <li>Test individual functions and classes</li> <li>Mock external dependencies</li> <li>Fast execution</li> </ul>"},{"location":"developer-guide/#integration-tests","title":"Integration Tests","text":"<ul> <li>Test component interactions</li> <li>Use real AI providers (with test keys)</li> <li>Moderate execution time</li> </ul>"},{"location":"developer-guide/#end-to-end-tests","title":"End-to-End Tests","text":"<ul> <li>Test complete workflows</li> <li>Use real files and AI providers</li> <li>Slower execution</li> </ul>"},{"location":"developer-guide/#writing-tests","title":"Writing Tests","text":""},{"location":"developer-guide/#test-fixtures","title":"Test Fixtures","text":"<pre><code>@pytest.fixture\ndef sample_pdf_document():\n    \"\"\"Create a sample PDF document for testing.\"\"\"\n    return PDFDocument(\n        file_path=Path(\"test.pdf\"),\n        text_content=\"Sample content\",\n        metadata={},\n        page_count=1,\n        extraction_method=\"pypdf\"\n    )\n</code></pre>"},{"location":"developer-guide/#mocking-ai-providers","title":"Mocking AI Providers","text":"<pre><code>@pytest.fixture\ndef mock_ai_providers():\n    \"\"\"Mock all AI providers for testing.\"\"\"\n    with patch('openai.OpenAI') as mock_openai:\n        mock_client = MagicMock()\n        mock_response = MagicMock()\n        mock_response.choices = [MagicMock()]\n        mock_response.choices[0].message.content = '{\"company_name\": \"Test\"}'\n        mock_client.chat.completions.create.return_value = mock_response\n        mock_openai.return_value = mock_client\n        yield mock_openai\n</code></pre>"},{"location":"developer-guide/#test-examples","title":"Test Examples","text":"<pre><code>def test_analyze_document(mock_ai_providers, sample_pdf_document):\n    \"\"\"Test document analysis.\"\"\"\n    analyzer = AIAnalyzer(provider='openai')\n    result = analyzer.analyze_document(sample_pdf_document)\n\n    assert result.company_name == \"Test\"\n    assert result.confidence_score &gt; 0.0\n</code></pre>"},{"location":"developer-guide/#contributing","title":"Contributing","text":""},{"location":"developer-guide/#development-workflow","title":"Development Workflow","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch: <code>git checkout -b feature/your-feature</code></li> <li>Make changes: Follow coding standards</li> <li>Write tests: Add tests for new functionality</li> <li>Run tests: Ensure all tests pass</li> <li>Commit changes: Use descriptive commit messages</li> <li>Push to fork: <code>git push origin feature/your-feature</code></li> <li>Create pull request: Submit PR for review</li> </ol>"},{"location":"developer-guide/#coding-standards","title":"Coding Standards","text":""},{"location":"developer-guide/#python-style","title":"Python Style","text":"<ul> <li>Follow PEP 8 style guidelines</li> <li>Use type hints for all functions</li> <li>Write docstrings for all public functions</li> <li>Keep functions small and focused</li> </ul>"},{"location":"developer-guide/#code-formatting_1","title":"Code Formatting","text":"<pre><code># Format code\nblack src tests\n\n# Sort imports\nisort src tests\n\n# Lint code\nflake8 src tests\n\n# Type check\nmypy src\n</code></pre>"},{"location":"developer-guide/#commit-messages","title":"Commit Messages","text":"<p>Use conventional commit format:</p> <pre><code>feat: add new AI provider support\nfix: resolve PDF processing error\ndocs: update installation guide\ntest: add integration tests\n</code></pre>"},{"location":"developer-guide/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<ol> <li>Clear title: Describe what the PR does</li> <li>Detailed description: Explain changes and motivation</li> <li>Link issues: Reference related issues</li> <li>Add tests: Include tests for new functionality</li> <li>Update docs: Update documentation if needed</li> </ol>"},{"location":"developer-guide/#code-review-process","title":"Code Review Process","text":""},{"location":"developer-guide/#for-contributors","title":"For Contributors","text":"<ul> <li>Address all review comments</li> <li>Keep commits focused and atomic</li> <li>Write clear commit messages</li> <li>Test your changes thoroughly</li> </ul>"},{"location":"developer-guide/#for-reviewers","title":"For Reviewers","text":"<ul> <li>Be constructive and helpful</li> <li>Check for security issues</li> <li>Verify test coverage</li> <li>Ensure documentation is updated</li> </ul>"},{"location":"developer-guide/#debugging","title":"Debugging","text":""},{"location":"developer-guide/#common-issues","title":"Common Issues","text":""},{"location":"developer-guide/#import-errors","title":"Import Errors","text":"<pre><code># Error: No module named 'src'\n# Solution: Install in development mode\npip install -e .\n</code></pre>"},{"location":"developer-guide/#configuration-errors","title":"Configuration Errors","text":"<pre><code># Error: Configuration not found\n# Solution: Check file paths and permissions\nls -la config.yaml\n</code></pre>"},{"location":"developer-guide/#ai-provider-errors","title":"AI Provider Errors","text":"<pre><code># Error: API key invalid\n# Solution: Check environment variables\necho $OPENAI_API_KEY\n</code></pre>"},{"location":"developer-guide/#debug-mode","title":"Debug Mode","text":"<pre><code># Enable debug logging\nexport LOG_LEVEL=DEBUG\n\n# Run with verbose output\npython cli.py --verbose\n\n# Check log files\ntail -f logs/app.log\n</code></pre>"},{"location":"developer-guide/#debugging-tools","title":"Debugging Tools","text":""},{"location":"developer-guide/#vs-code-debugging","title":"VS Code Debugging","text":"<ol> <li>Set breakpoints: Click in the gutter</li> <li>Start debugging: Press F5</li> <li>Step through code: Use F10, F11</li> <li>Inspect variables: Hover over variables</li> </ol>"},{"location":"developer-guide/#pycharm-debugging","title":"PyCharm Debugging","text":"<ol> <li>Set breakpoints: Click in the gutter</li> <li>Start debugging: Click debug button</li> <li>Step through code: Use step buttons</li> <li>Inspect variables: Use variables panel</li> </ol>"},{"location":"developer-guide/#logging","title":"Logging","text":"<pre><code>import logging\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\n# Use logger\nlogger = logging.getLogger(__name__)\nlogger.debug(\"Debug message\")\nlogger.info(\"Info message\")\nlogger.error(\"Error message\")\n</code></pre>"},{"location":"developer-guide/#performance-optimization","title":"Performance Optimization","text":""},{"location":"developer-guide/#profiling","title":"Profiling","text":""},{"location":"developer-guide/#cpu-profiling","title":"CPU Profiling","text":"<pre><code># Install profiling tools\npip install cProfile\n\n# Profile CLI execution\npython -m cProfile -o profile.stats cli.py --dry-run\n\n# Analyze results\npython -c \"import pstats; pstats.Stats('profile.stats').sort_stats('cumulative').print_stats(10)\"\n</code></pre>"},{"location":"developer-guide/#memory-profiling","title":"Memory Profiling","text":"<pre><code># Install memory profiler\npip install memory-profiler\n\n# Profile memory usage\npython -m memory_profiler cli.py\n</code></pre>"},{"location":"developer-guide/#optimization-strategies","title":"Optimization Strategies","text":""},{"location":"developer-guide/#batch-processing","title":"Batch Processing","text":"<pre><code># Process files in batches\ndef process_batch(files, batch_size=10):\n    for i in range(0, len(files), batch_size):\n        batch = files[i:i + batch_size]\n        process_files(batch)\n</code></pre>"},{"location":"developer-guide/#caching","title":"Caching","text":"<pre><code>from functools import lru_cache\n\n@lru_cache(maxsize=128)\ndef analyze_document_cached(text: str) -&gt; DocumentInfo:\n    \"\"\"Cached document analysis.\"\"\"\n    return analyzer.analyze_document_text(text)\n</code></pre>"},{"location":"developer-guide/#async-processing","title":"Async Processing","text":"<pre><code>import asyncio\n\nasync def process_documents_async(documents):\n    \"\"\"Process documents asynchronously.\"\"\"\n    tasks = [analyze_document_async(doc) for doc in documents]\n    results = await asyncio.gather(*tasks)\n    return results\n</code></pre>"},{"location":"developer-guide/#monitoring","title":"Monitoring","text":""},{"location":"developer-guide/#performance-metrics","title":"Performance Metrics","text":"<pre><code>import time\nfrom contextlib import contextmanager\n\n@contextmanager\ndef timer(name):\n    start = time.time()\n    yield\n    print(f\"{name} took {time.time() - start:.2f} seconds\")\n\n# Usage\nwith timer(\"Document processing\"):\n    result = process_document(document)\n</code></pre>"},{"location":"developer-guide/#resource-monitoring","title":"Resource Monitoring","text":"<pre><code># Monitor CPU and memory\nhtop\n\n# Monitor disk usage\ndf -h\n\n# Monitor network usage\niftop\n</code></pre>"},{"location":"developer-guide/#advanced-topics","title":"Advanced Topics","text":""},{"location":"developer-guide/#custom-ai-providers","title":"Custom AI Providers","text":"<pre><code>class CustomAIProvider:\n    def analyze_document_text(self, text: str, max_tokens: int = 800) -&gt; str:\n        \"\"\"Custom AI provider implementation.\"\"\"\n        # Your custom logic here\n        return json.dumps({\n            \"company_name\": \"Custom Company\",\n            \"document_type\": \"custom type\",\n            \"confidence_score\": 0.9\n        })\n</code></pre>"},{"location":"developer-guide/#plugin-system","title":"Plugin System","text":"<pre><code>class PluginManager:\n    def __init__(self):\n        self.plugins = []\n\n    def register_plugin(self, plugin):\n        self.plugins.append(plugin)\n\n    def process_document(self, document):\n        for plugin in self.plugins:\n            document = plugin.process(document)\n        return document\n</code></pre>"},{"location":"developer-guide/#api-development","title":"API Development","text":"<pre><code>from flask import Flask, request, jsonify\n\napp = Flask(__name__)\n\n@app.route('/api/analyze', methods=['POST'])\ndef analyze_document():\n    data = request.json\n    file_path = data.get('file_path')\n\n    # Process document\n    processor = PDFProcessor()\n    document = processor.process_pdf(Path(file_path))\n\n    analyzer = AIAnalyzer(provider='openai')\n    result = analyzer.analyze_document(document)\n\n    return jsonify(result.__dict__)\n</code></pre>"},{"location":"developer-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"developer-guide/#common-development-issues","title":"Common Development Issues","text":""},{"location":"developer-guide/#virtual-environment-issues","title":"Virtual Environment Issues","text":"<pre><code># Error: Command not found\n# Solution: Activate virtual environment\nsource venv/bin/activate\n\n# Error: Package not found\n# Solution: Install in development mode\npip install -e .[dev]\n</code></pre>"},{"location":"developer-guide/#import-issues","title":"Import Issues","text":"<pre><code># Error: Module not found\n# Solution: Check Python path\npython -c \"import sys; print(sys.path)\"\n\n# Error: Circular imports\n# Solution: Restructure imports\n</code></pre>"},{"location":"developer-guide/#test-issues","title":"Test Issues","text":"<pre><code># Error: Tests not found\n# Solution: Check test discovery\npytest --collect-only\n\n# Error: Import errors in tests\n# Solution: Check test configuration\n</code></pre>"},{"location":"developer-guide/#getting-help","title":"Getting Help","text":"<ol> <li>Check documentation: Review relevant docs</li> <li>Search issues: Look for similar problems</li> <li>Create issue: Provide detailed information</li> <li>Ask community: Use discussions or chat</li> </ol>"},{"location":"developer-guide/#support-channels","title":"Support Channels","text":"<ul> <li>GitHub Issues: Project Issues</li> <li>Discussions: GitHub Discussions</li> <li>Documentation: Project Docs</li> </ul>"},{"location":"developer-guide/#next-steps","title":"Next Steps","text":"<p>After setting up your development environment:</p> <ol> <li>Explore the codebase: Read through the source code</li> <li>Run tests: Ensure everything works</li> <li>Make a small change: Try modifying something</li> <li>Write a test: Add a test for your change</li> <li>Submit a PR: Contribute your changes</li> </ol>"},{"location":"developer-guide/#resources","title":"Resources","text":"<ul> <li>Python Documentation: https://docs.python.org</li> <li>Pytest Documentation: https://docs.pytest.org</li> <li>Flask Documentation: https://flask.palletsprojects.com</li> <li>OpenAI API Documentation: https://platform.openai.com/docs</li> <li>Anthropic API Documentation: https://docs.anthropic.com</li> </ul>"},{"location":"installation/","title":"Installation Guide","text":"<p>This guide will help you install and set up the OCRganizer system on your machine.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":""},{"location":"installation/#system-requirements","title":"System Requirements","text":"<ul> <li>Python: 3.9 or higher</li> <li>Operating System: Windows, macOS, or Linux</li> <li>Memory: At least 4GB RAM (8GB recommended for local AI models)</li> <li>Storage: 2GB free space for dependencies</li> </ul>"},{"location":"installation/#system-dependencies","title":"System Dependencies","text":"<p>The system requires several external tools for PDF processing and OCR:</p>"},{"location":"installation/#macos","title":"macOS","text":"<pre><code># Install using Homebrew\nbrew install poppler tesseract\n\n# Optional: Install additional language packs\nbrew install tesseract-lang\n</code></pre>"},{"location":"installation/#ubuntudebian","title":"Ubuntu/Debian","text":"<pre><code># Update package list\nsudo apt-get update\n\n# Install required packages\nsudo apt-get install -y poppler-utils tesseract-ocr\n\n# Optional: Install additional language packs\nsudo apt-get install -y tesseract-ocr-eng tesseract-ocr-spa\n</code></pre>"},{"location":"installation/#windows","title":"Windows","text":"<pre><code># Install using Chocolatey\nchoco install poppler tesseract\n\n# Or download from:\n# Poppler: https://blog.alivate.com.au/poppler-windows/\n# Tesseract: https://github.com/UB-Mannheim/tesseract/wiki\n</code></pre>"},{"location":"installation/#installation-methods","title":"Installation Methods","text":""},{"location":"installation/#method-1-development-installation-recommended","title":"Method 1: Development Installation (Recommended)","text":"<p>This method installs the package in development mode, allowing you to make changes to the code.</p> <pre><code># Clone the repository\ngit clone https://github.com/yourusername/OCRganizer.git\ncd OCRganizer\n\n# Create a virtual environment\npython -m venv venv\n\n# Activate virtual environment\n# On Windows:\nvenv\\Scripts\\activate\n# On macOS/Linux:\nsource venv/bin/activate\n\n# Install in development mode with all dependencies\npip install -e .[dev]\n\n# Verify installation\npython -c \"import src.ai_analyzer; print('Installation successful!')\"\n</code></pre>"},{"location":"installation/#method-2-production-installation","title":"Method 2: Production Installation","text":"<p>For production use or if you don't need to modify the code:</p> <pre><code># Install from PyPI (when published)\npip install OCRganizer\n\n# Or install from GitHub\npip install git+https://github.com/yourusername/OCRganizer.git\n</code></pre>"},{"location":"installation/#method-3-docker-installation","title":"Method 3: Docker Installation","text":"<pre><code># Build the Docker image\ndocker build -t OCRganizer .\n\n# Run the web interface\ndocker run -p 5000:5000 -v $(pwd)/input_pdfs:/app/input_pdfs OCRganizer\n</code></pre>"},{"location":"installation/#configuration","title":"Configuration","text":""},{"location":"installation/#1-environment-setup","title":"1. Environment Setup","text":"<p>Copy the example environment file and configure it:</p> <pre><code>cp env.example env\n</code></pre> <p>\ud83d\udcd6 For detailed AI provider setup instructions, see AI Provider Setup</p>"},{"location":"installation/#2-application-configuration","title":"2. Application Configuration","text":"<p>The system uses <code>config.yaml</code> for application settings. For detailed configuration options, see Configuration Reference.</p>"},{"location":"installation/#verification","title":"Verification","text":""},{"location":"installation/#test-the-installation","title":"Test the Installation","text":"<p>Run the test suite to verify everything is working:</p> <pre><code># Run all tests\npytest\n\n# Run with coverage\npytest --cov=src --cov-report=html\n\n# Run specific test categories\npytest -m \"not slow\"  # Skip slow tests\npytest tests/test_pdf_processor.py  # Test specific module\n</code></pre>"},{"location":"installation/#test-ai-provider","title":"Test AI Provider","text":"<p>\ud83d\udcd6 For AI provider testing instructions, see AI Provider Setup</p>"},{"location":"installation/#test-pdf-processing","title":"Test PDF Processing","text":"<pre><code># Test with a sample PDF\npython cli.py --dry-run --input input_pdfs/\n</code></pre>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":"<p>\ud83d\udcd6 For comprehensive troubleshooting, see Troubleshooting Guide</p>"},{"location":"installation/#next-steps","title":"Next Steps","text":"<p>Once installation is complete:</p> <ol> <li>Read the User Guide for usage instructions</li> <li>Configure your AI provider in the <code>env</code> file</li> <li>Test with sample PDFs in the <code>input_pdfs/</code> directory</li> <li>Explore the API Documentation for advanced usage</li> </ol>"},{"location":"lm-studio-setup/","title":"LM Studio Integration Guide","text":"<p>This guide shows you how to use your local Mac's LM Studio instance instead of OpenAI's cloud API for document analysis.</p>"},{"location":"lm-studio-setup/#prerequisites","title":"Prerequisites","text":"<ol> <li>LM Studio installed on your Mac</li> <li>A suitable model loaded in LM Studio (recommended: Llama 2 7B, Mistral 7B, or similar)</li> <li>LM Studio server running with API enabled</li> </ol>"},{"location":"lm-studio-setup/#step-1-configure-lm-studio","title":"Step 1: Configure LM Studio","text":"<ol> <li>Open LM Studio on your Mac</li> <li>Load a Model: Download and load a suitable model (e.g., <code>microsoft/DialoGPT-medium</code>, <code>mistralai/Mistral-7B-Instruct-v0.1</code>)</li> <li>Start the Server:</li> <li>Go to the \"Local Server\" tab</li> <li>Click \"Start Server\"</li> <li>Note the port (usually <code>1234</code>)</li> <li>Ensure \"Cross-Origin Resource Sharing (CORS)\" is enabled if needed</li> </ol>"},{"location":"lm-studio-setup/#step-2-configure-your-environment","title":"Step 2: Configure Your Environment","text":"<p>Edit your <code>.env</code> file:</p> <pre><code># Comment out or remove OpenAI cloud configuration\n# OPENAI_API_KEY=your_openai_api_key_here\n\n# Add LM Studio configuration\nOPENAI_BASE_URL=http://localhost:1234/v1\nOPENAI_API_KEY=lm-studio\nLOCAL_MODEL_NAME=your-loaded-model-name\n</code></pre> <p>Important: Replace <code>your-loaded-model-name</code> with the actual model name shown in LM Studio.</p>"},{"location":"lm-studio-setup/#step-3-find-your-model-name","title":"Step 3: Find Your Model Name","text":"<p>In LM Studio: 1. Go to \"Local Server\" tab 2. Look for the model name in the \"Loaded Model\" section 3. Common formats:    - <code>microsoft/DialoGPT-medium</code>    - <code>mistralai/Mistral-7B-Instruct-v0.1</code>    - <code>TheBloke/Llama-2-7B-Chat-GGML</code></p>"},{"location":"lm-studio-setup/#step-4-test-the-configuration","title":"Step 4: Test the Configuration","text":"<p>Run a quick test:</p> <pre><code># Test with preview mode\n./preview_pdfs.sh\n</code></pre> <p>You should see log messages indicating: <pre><code>Using local LM Studio instance at http://localhost:1234/v1\nUsing model: your-loaded-model-name\n</code></pre></p>"},{"location":"lm-studio-setup/#recommended-models-for-document-analysis","title":"Recommended Models for Document Analysis","text":""},{"location":"lm-studio-setup/#best-performance-if-your-mac-can-handle-it","title":"Best Performance (if your Mac can handle it):","text":"<ul> <li>Llama 2 13B Chat - Excellent reasoning</li> <li>Mistral 7B Instruct - Good balance of speed/quality</li> <li>Code Llama 7B - Good for structured output</li> </ul>"},{"location":"lm-studio-setup/#good-performance-lighter-weight","title":"Good Performance (lighter weight):","text":"<ul> <li>Llama 2 7B Chat - Reliable, well-tested</li> <li>Vicuna 7B - Good instruction following</li> <li>OpenHermes 2.5 7B - Good for JSON output</li> </ul>"},{"location":"lm-studio-setup/#fast-performance-for-older-macs","title":"Fast Performance (for older Macs):","text":"<ul> <li>TinyLlama 1.1B - Very fast but less accurate</li> <li>Phi-2 2.7B - Good reasoning for size</li> </ul>"},{"location":"lm-studio-setup/#configuration-examples","title":"Configuration Examples","text":""},{"location":"lm-studio-setup/#for-llama-2-7b-chat","title":"For Llama 2 7B Chat:","text":"<pre><code>OPENAI_BASE_URL=http://localhost:1234/v1\nOPENAI_API_KEY=lm-studio\nLOCAL_MODEL_NAME=llama-2-7b-chat\nOPENAI_MODEL=llama-2-7b-chat\n</code></pre>"},{"location":"lm-studio-setup/#for-mistral-7b-instruct","title":"For Mistral 7B Instruct:","text":"<pre><code>OPENAI_BASE_URL=http://localhost:1234/v1\nOPENAI_API_KEY=lm-studio\nLOCAL_MODEL_NAME=mistral-7b-instruct-v0.1\nOPENAI_MODEL=mistral-7b-instruct-v0.1\n</code></pre>"},{"location":"lm-studio-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"lm-studio-setup/#connection-issues","title":"Connection Issues","text":"<ul> <li>Ensure LM Studio server is running</li> <li>Check the port number (default: 1234)</li> <li>Verify firewall isn't blocking the connection</li> </ul>"},{"location":"lm-studio-setup/#model-not-found","title":"Model Not Found","text":"<ul> <li>Check the exact model name in LM Studio</li> <li>Update <code>LOCAL_MODEL_NAME</code> in your <code>.env</code> file</li> <li>Some models may use different naming conventions</li> </ul>"},{"location":"lm-studio-setup/#poor-results","title":"Poor Results","text":"<ul> <li>Try a larger model if your Mac can handle it</li> <li>Adjust temperature settings in the code (currently 0.3)</li> <li>Ensure the model is designed for instruction following</li> </ul>"},{"location":"lm-studio-setup/#performance-issues","title":"Performance Issues","text":"<ul> <li>Use GPU acceleration if available</li> <li>Consider a smaller model for faster processing</li> <li>Adjust <code>max_tokens</code> if responses are being cut off</li> </ul>"},{"location":"lm-studio-setup/#benefits-of-using-lm-studio","title":"Benefits of Using LM Studio","text":"<p>\u2705 Privacy: All processing happens locally on your Mac \u2705 No API Costs: No charges for API usage \u2705 Offline Operation: Works without internet connection \u2705 Customization: Use any compatible model you prefer \u2705 Speed: Can be faster than cloud APIs (depending on your hardware)</p>"},{"location":"lm-studio-setup/#switching-back-to-openai","title":"Switching Back to OpenAI","text":"<p>To switch back to OpenAI's cloud service:</p> <pre><code># Restore OpenAI configuration\nOPENAI_API_KEY=your_actual_openai_key\n# OPENAI_BASE_URL=http://localhost:1234/v1  # Comment out\n</code></pre>"},{"location":"lm-studio-setup/#performance-tips","title":"Performance Tips","text":"<ol> <li>Use GPU acceleration in LM Studio if available</li> <li>Close other applications to free up RAM for the model</li> <li>Use smaller models for faster processing of large batches</li> <li>Monitor CPU/GPU usage to find the right balance</li> </ol> <p>Your OCRganizer will now use your local LM Studio instance for all document analysis! \ud83d\ude80</p>"},{"location":"quick-start/","title":"Quick Start Guide","text":"<p>Get the OCRganizer running in 5 minutes! This guide provides the essential steps to get started quickly.</p>"},{"location":"quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9+ installed on your system</li> <li>Git for cloning the repository</li> <li>AI Provider API Key (see AI Provider Setup for detailed instructions)</li> </ul>"},{"location":"quick-start/#step-1-clone-and-setup","title":"Step 1: Clone and Setup","text":"<pre><code># Clone the repository\ngit clone https://github.com/yourusername/OCRganizer.git\ncd OCRganizer\n\n# Create virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install dependencies\npip install -e .[dev]\n</code></pre>"},{"location":"quick-start/#step-2-install-system-dependencies","title":"Step 2: Install System Dependencies","text":"<p>macOS: <code>brew install poppler tesseract</code> Ubuntu/Debian: <code>sudo apt-get install poppler-utils tesseract-ocr</code> Windows: <code>choco install poppler tesseract</code></p> <p>\ud83d\udcd6 For detailed system dependency installation, see Installation Guide</p>"},{"location":"quick-start/#step-3-configure-ai-provider","title":"Step 3: Configure AI Provider","text":"<p>Quick setup for OpenAI (recommended for beginners):</p> <pre><code># Copy environment template\ncp env.example env\n\n# Edit env file and add your OpenAI API key\n# Get your API key from: https://platform.openai.com/api-keys\nOPENAI_API_KEY=sk-your-actual-api-key-here\n</code></pre> <p>\ud83d\udcd6 For detailed AI provider setup (OpenAI, Anthropic, LM Studio), see AI Provider Setup</p>"},{"location":"quick-start/#step-4-test-and-start","title":"Step 4: Test and Start","text":"<pre><code># Test the installation\npython cli.py --dry-run\n\n# Start processing (web interface)\npython app.py\n# Visit http://localhost:5000\n\n# Or use command line\npython cli.py\n</code></pre>"},{"location":"quick-start/#next-steps","title":"Next Steps","text":"<ul> <li>Learn more: Read the User Guide for detailed usage</li> <li>Configure: See Configuration Reference for advanced settings</li> <li>Troubleshoot: Check Troubleshooting Guide if you encounter issues</li> </ul>"},{"location":"troubleshooting/","title":"Troubleshooting Guide","text":"<p>This guide helps you resolve common issues with the OCRganizer system.</p>"},{"location":"troubleshooting/#installation-issues","title":"Installation Issues","text":""},{"location":"troubleshooting/#python-version-problems","title":"Python Version Problems","text":"<p>Error: <code>Python 3.9+ required</code></p> <p>Solution: <pre><code># Check current Python version\npython --version\n\n# Install Python 3.9+ if needed\n# macOS\nbrew install python@3.11\n\n# Ubuntu/Debian\nsudo apt-get install python3.11\n\n# Use pyenv for version management\npyenv install 3.11.0\npyenv local 3.11.0\n</code></pre></p>"},{"location":"troubleshooting/#virtual-environment-issues","title":"Virtual Environment Issues","text":"<p>Error: <code>No module named 'src'</code></p> <p>Solution: <pre><code># Create and activate virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install in development mode\npip install -e .[dev]\n</code></pre></p>"},{"location":"troubleshooting/#system-dependencies","title":"System Dependencies","text":"<p>Error: <code>Tesseract not found</code></p> <p>Solution: <pre><code># macOS\nbrew install tesseract\n\n# Ubuntu/Debian\nsudo apt-get install tesseract-ocr\n\n# Windows\nchoco install tesseract\n</code></pre></p> <p>Error: <code>pdftoppm not found</code></p> <p>Solution: <pre><code># macOS\nbrew install poppler\n\n# Ubuntu/Debian\nsudo apt-get install poppler-utils\n\n# Windows\nchoco install poppler\n</code></pre></p>"},{"location":"troubleshooting/#configuration-issues","title":"Configuration Issues","text":""},{"location":"troubleshooting/#environment-variables","title":"Environment Variables","text":"<p>Error: <code>API key not found</code></p> <p>Solution: <pre><code># Check if env file exists\nls -la env\n\n# Copy example if missing\ncp env.example env\n\n# Edit with your API key\nnano env\n</code></pre></p> <p>Error: <code>Invalid configuration</code></p> <p>Solution: <pre><code># Check YAML syntax\npython -c \"import yaml; yaml.safe_load(open('config.yaml'))\"\n\n# Validate configuration\npython -c \"from src.config import get_config; print(get_config())\"\n</code></pre></p>"},{"location":"troubleshooting/#ai-provider-issues","title":"AI Provider Issues","text":"<p>Error: <code>OpenAI API key invalid</code></p> <p>Solution: <pre><code># Check API key format\necho $OPENAI_API_KEY\n\n# Verify key is valid\ncurl -H \"Authorization: Bearer $OPENAI_API_KEY\" https://api.openai.com/v1/models\n</code></pre></p> <p>Error: <code>Anthropic API key invalid</code></p> <p>Solution: <pre><code># Check API key format\necho $ANTHROPIC_API_KEY\n\n# Verify key is valid\ncurl -H \"x-api-key: $ANTHROPIC_API_KEY\" https://api.anthropic.com/v1/messages\n</code></pre></p> <p>Error: <code>LM Studio connection failed</code></p> <p>Solution: <pre><code># Check if LM Studio is running\ncurl http://localhost:1234/v1/models\n\n# Verify configuration\necho $OPENAI_BASE_URL\necho $LOCAL_MODEL_NAME\n</code></pre></p>"},{"location":"troubleshooting/#processing-issues","title":"Processing Issues","text":""},{"location":"troubleshooting/#pdf-processing-errors","title":"PDF Processing Errors","text":"<p>Error: <code>PDF processing failed</code></p> <p>Solution: <pre><code># Check file permissions\nls -la input_pdfs/\n\n# Test with a simple PDF\npython -c \"from src.pdf_processor import PDFProcessor; p = PDFProcessor(); print(p.process_pdf('test.pdf'))\"\n</code></pre></p> <p>Error: <code>OCR processing failed</code></p> <p>Solution: <pre><code># Check Tesseract installation\ntesseract --version\n\n# Test OCR with a simple image\ntesseract test.png output.txt\n</code></pre></p>"},{"location":"troubleshooting/#ai-analysis-errors","title":"AI Analysis Errors","text":"<p>Error: <code>AI analysis failed</code></p> <p>Solution: <pre><code># Check API key\necho $OPENAI_API_KEY\n\n# Test AI provider\npython -c \"from src.ai_analyzer import AIAnalyzer; a = AIAnalyzer('openai'); print('AI provider working')\"\n</code></pre></p> <p>Error: <code>Low confidence scores</code></p> <p>Solution: - Try different AI providers - Adjust confidence threshold in config - Check document quality (scanning, text clarity) - Use higher resolution scans</p>"},{"location":"troubleshooting/#file-organization-errors","title":"File Organization Errors","text":"<p>Error: <code>File organization failed</code></p> <p>Solution: <pre><code># Check output directory permissions\nls -la output/\n\n# Test with dry run\npython cli.py --dry-run\n\n# Check disk space\ndf -h\n</code></pre></p> <p>Error: <code>Invalid filename pattern</code></p> <p>Solution: <pre><code># Check pattern syntax\npython -c \"from src.config import get_config; print(get_config().organization.filename_pattern)\"\n\n# Test pattern with sample data\npython -c \"from src.file_organizer import FileOrganizer; print('Pattern validation')\"\n</code></pre></p>"},{"location":"troubleshooting/#web-interface-issues","title":"Web Interface Issues","text":""},{"location":"troubleshooting/#flask-app-errors","title":"Flask App Errors","text":"<p>Error: <code>Flask app not starting</code></p> <p>Solution: <pre><code># Check port availability\nlsof -i :5000\n\n# Try different port\npython app.py --port 5001\n\n# Check Flask installation\npip install flask\n</code></pre></p> <p>Error: <code>File upload failed</code></p> <p>Solution: <pre><code># Check file size limits\npython -c \"from src.config import get_config; print(get_config().web.max_upload_size)\"\n\n# Check file permissions\nls -la input_pdfs/\n</code></pre></p>"},{"location":"troubleshooting/#browser-issues","title":"Browser Issues","text":"<p>Error: <code>Page not loading</code></p> <p>Solution: - Check if Flask app is running - Try different browser - Clear browser cache - Check firewall settings</p>"},{"location":"troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"troubleshooting/#slow-processing","title":"Slow Processing","text":"<p>Symptoms: Long processing times, high memory usage</p> <p>Solution: <pre><code># Reduce batch size\npython cli.py --batch-size 5\n\n# Use faster AI provider\nexport PREFERRED_AI_PROVIDER=openai\n\n# Check system resources\ntop\nhtop\n</code></pre></p>"},{"location":"troubleshooting/#memory-issues","title":"Memory Issues","text":"<p>Error: <code>Out of memory</code></p> <p>Solution: <pre><code># Reduce batch size in config\n# Check available memory\nfree -h\n\n# Process smaller files\npython cli.py --max-file-size 10\n</code></pre></p>"},{"location":"troubleshooting/#network-issues","title":"Network Issues","text":"<p>Error: <code>API timeout</code></p> <p>Solution: <pre><code># Check internet connection\nping api.openai.com\n\n# Increase timeout in config\n# Use local AI provider (LM Studio)\n</code></pre></p>"},{"location":"troubleshooting/#logging-and-debugging","title":"Logging and Debugging","text":""},{"location":"troubleshooting/#enable-debug-mode","title":"Enable Debug Mode","text":"<pre><code># Set debug environment variable\nexport LOG_LEVEL=DEBUG\n\n# Run with verbose output\npython cli.py --verbose\n\n# Check log files\ntail -f logs/app.log\n</code></pre>"},{"location":"troubleshooting/#common-log-messages","title":"Common Log Messages","text":"<p>INFO: <code>Processing document: document.pdf</code> - Normal processing message</p> <p>WARNING: <code>Low confidence score: 0.3</code> - AI analysis has low confidence</p> <p>ERROR: <code>AI analysis failed: API key invalid</code> - AI provider authentication failed</p> <p>CRITICAL: <code>Out of memory</code> - System resource exhaustion</p>"},{"location":"troubleshooting/#debug-commands","title":"Debug Commands","text":"<pre><code># Test configuration loading\npython -c \"from src.config import get_config; print(get_config())\"\n\n# Test AI provider\npython -c \"from src.ai_analyzer import AIAnalyzer; a = AIAnalyzer('openai'); print('AI working')\"\n\n# Test PDF processing\npython -c \"from src.pdf_processor import PDFProcessor; p = PDFProcessor(); print('PDF processing working')\"\n\n# Test file organization\npython -c \"from src.file_organizer import FileOrganizer; o = FileOrganizer(); print('File organization working')\"\n</code></pre>"},{"location":"troubleshooting/#platform-specific-issues","title":"Platform-Specific Issues","text":""},{"location":"troubleshooting/#macos-issues","title":"macOS Issues","text":"<p>Error: <code>Permission denied</code></p> <p>Solution: <pre><code># Grant permissions to Terminal\n# System Preferences &gt; Security &amp; Privacy &gt; Privacy &gt; Full Disk Access\n\n# Check file permissions\nls -la input_pdfs/\nchmod 755 input_pdfs/\n</code></pre></p> <p>Error: <code>Homebrew not found</code></p> <p>Solution: <pre><code># Install Homebrew\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n# Install dependencies\nbrew install poppler tesseract\n</code></pre></p>"},{"location":"troubleshooting/#windows-issues","title":"Windows Issues","text":"<p>Error: <code>Command not found</code></p> <p>Solution: <pre><code># Install Chocolatey\nSet-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))\n\n# Install dependencies\nchoco install poppler tesseract\n</code></pre></p> <p>Error: <code>Path too long</code></p> <p>Solution: - Use shorter directory paths - Enable long path support in Windows - Use WSL for development</p>"},{"location":"troubleshooting/#linux-issues","title":"Linux Issues","text":"<p>Error: <code>Package not found</code></p> <p>Solution: <pre><code># Update package list\nsudo apt-get update\n\n# Install dependencies\nsudo apt-get install poppler-utils tesseract-ocr\n\n# For other distributions, use appropriate package manager\n</code></pre></p>"},{"location":"troubleshooting/#security-issues","title":"Security Issues","text":""},{"location":"troubleshooting/#api-key-security","title":"API Key Security","text":"<p>Error: <code>API key exposed in logs</code></p> <p>Solution: <pre><code># Check for exposed keys\ngrep -r \"sk-\" logs/\ngrep -r \"api_key\" logs/\n\n# Use environment variables\nexport OPENAI_API_KEY=your_key_here\n</code></pre></p>"},{"location":"troubleshooting/#file-security","title":"File Security","text":"<p>Error: <code>Permission denied</code></p> <p>Solution: <pre><code># Check file permissions\nls -la input_pdfs/\nls -la output/\n\n# Set appropriate permissions\nchmod 755 input_pdfs/\nchmod 755 output/\n</code></pre></p>"},{"location":"troubleshooting/#getting-help","title":"Getting Help","text":""},{"location":"troubleshooting/#self-diagnosis","title":"Self-Diagnosis","text":"<ol> <li>Check logs: Look for error messages in log files</li> <li>Test components: Run debug commands to test each component</li> <li>Verify configuration: Ensure all settings are correct</li> <li>Check dependencies: Ensure all required packages are installed</li> </ol>"},{"location":"troubleshooting/#community-support","title":"Community Support","text":"<ol> <li>GitHub Issues: Create an issue with detailed error information</li> <li>Documentation: Check this guide and other documentation</li> <li>Stack Overflow: Search for similar issues</li> <li>Discord/Slack: Join community channels if available</li> </ol>"},{"location":"troubleshooting/#reporting-issues","title":"Reporting Issues","text":"<p>When reporting issues, include:</p> <ol> <li>Error message: Complete error message and stack trace</li> <li>System information: OS, Python version, package versions</li> <li>Configuration: Relevant configuration settings</li> <li>Steps to reproduce: Detailed steps to reproduce the issue</li> <li>Log files: Relevant log entries</li> </ol>"},{"location":"troubleshooting/#example-issue-report","title":"Example Issue Report","text":"<p><pre><code>Title: AI analysis failing with OpenAI API\n\nDescription:\nGetting \"API key invalid\" error when trying to analyze documents.\n\nError:\n</code></pre> Traceback (most recent call last):   File \"src/ai_analyzer.py\", line 45, in analyze_document     response = self.client.chat.completions.create(...) openai.AuthenticationError: Invalid API key <pre><code>System:\n- OS: macOS 13.0\n- Python: 3.11.0\n- Package version: 1.0.0\n\nConfiguration:\n- AI Provider: OpenAI\n- API Key: sk-... (masked)\n\nSteps to reproduce:\n1. Set OPENAI_API_KEY in env file\n2. Run: python cli.py --dry-run\n3. Error occurs during AI analysis\n\nLogs:\n[2023-05-15 10:30:00] ERROR: AI analysis failed: Invalid API key\n</code></pre></p>"},{"location":"troubleshooting/#prevention","title":"Prevention","text":""},{"location":"troubleshooting/#best-practices","title":"Best Practices","text":"<ol> <li>Regular updates: Keep dependencies updated</li> <li>Backup configuration: Backup your configuration files</li> <li>Monitor logs: Regularly check log files for issues</li> <li>Test changes: Test configuration changes before deployment</li> <li>Document setup: Keep notes of your configuration</li> </ol>"},{"location":"troubleshooting/#maintenance","title":"Maintenance","text":"<ol> <li>Clean logs: Regularly clean old log files</li> <li>Update dependencies: Keep packages updated</li> <li>Monitor performance: Watch for performance degradation</li> <li>Backup data: Regular backups of important data</li> <li>Security updates: Apply security patches promptly</li> </ol>"},{"location":"user-guide/","title":"User Guide","text":"<p>This guide provides comprehensive instructions for using the OCRganizer system.</p>"},{"location":"user-guide/#getting-started","title":"Getting Started","text":"<p>\ud83d\udcd6 For installation and setup instructions, see Quick Start Guide or Installation Guide</p>"},{"location":"user-guide/#web-interface","title":"Web Interface","text":""},{"location":"user-guide/#starting-the-web-server","title":"Starting the Web Server","text":"<pre><code>python app.py\n</code></pre> <p>The web interface will be available at <code>http://localhost:5000</code>.</p>"},{"location":"user-guide/#web-interface-features","title":"Web Interface Features","text":"<ul> <li>Drag &amp; Drop: Upload PDFs directly to the interface</li> <li>Batch Processing: Process multiple files at once</li> <li>Preview Mode: See organization results before applying</li> <li>Progress Tracking: Real-time processing status</li> <li>Configuration: Adjust settings through the web interface</li> </ul>"},{"location":"user-guide/#web-interface-usage","title":"Web Interface Usage","text":"<ol> <li>Upload PDFs: Drag and drop files or click to browse</li> <li>Configure Settings: Adjust AI provider and processing options</li> <li>Preview Results: Review suggested organization before applying</li> <li>Process Files: Apply the organization to your files</li> </ol>"},{"location":"user-guide/#command-line-interface","title":"Command Line Interface","text":""},{"location":"user-guide/#basic-usage","title":"Basic Usage","text":"<pre><code># Process all PDFs in input_pdfs/\npython cli.py\n\n# Preview without moving files\npython cli.py --dry-run\n\n# Custom input/output directories\npython cli.py --input /path/to/pdfs --output /path/to/organized\n</code></pre>"},{"location":"user-guide/#cli-options","title":"CLI Options","text":"<pre><code>python cli.py [OPTIONS]\n\nOptions:\n  --input PATH              Input directory (default: input_pdfs/)\n  --output PATH             Output directory (default: output/)\n  --dry-run                 Preview changes without moving files\n  --copy                    Copy files instead of moving\n  --confidence-threshold FLOAT  Minimum confidence for auto-processing\n  --structure PATTERN       Custom folder structure pattern\n  --filename PATTERN        Custom filename pattern\n  --json-output PATH        Save results to JSON file\n  --verbose                 Enable verbose output\n  --help                    Show help message\n</code></pre>"},{"location":"user-guide/#advanced-cli-usage","title":"Advanced CLI Usage","text":"<p>Custom Organization Patterns: <pre><code># Use custom folder structure\npython cli.py --structure \"{company}/{type}/{year}\"\n\n# Use custom filename pattern\npython cli.py --filename \"{date}_{company}_{type}\"\n</code></pre></p> <p>Batch Processing with Filtering: <pre><code># Only process high-confidence results\npython cli.py --confidence-threshold 0.8\n\n# Copy instead of move files\npython cli.py --copy\n\n# Save detailed results to JSON\npython cli.py --json-output results.json\n</code></pre></p>"},{"location":"user-guide/#configuration","title":"Configuration","text":"<p>\ud83d\udcd6 For detailed configuration options, see Configuration Reference</p>"},{"location":"user-guide/#ai-providers","title":"AI Providers","text":"<p>\ud83d\udcd6 For detailed AI provider setup and comparison, see AI Provider Setup</p>"},{"location":"user-guide/#file-organization","title":"File Organization","text":""},{"location":"user-guide/#default-structure","title":"Default Structure","text":"<p>The system creates organized folder structures like:</p> <pre><code>output/\n\u251c\u2500\u2500 Chase_Bank/\n\u2502   \u2514\u2500\u2500 2023/\n\u2502       \u251c\u2500\u2500 03/\n\u2502       \u2502   \u251c\u2500\u2500 2023-03-15_Chase_Bank_Statement.pdf\n\u2502       \u2502   \u2514\u2500\u2500 2023-03-20_Chase_Bank_Credit_Card_Statement.pdf\n\u2502       \u2514\u2500\u2500 04/\n\u2502           \u2514\u2500\u2500 2023-04-15_Chase_Bank_Statement.pdf\n\u2514\u2500\u2500 Wells_Fargo/\n    \u2514\u2500\u2500 2023/\n        \u2514\u2500\u2500 05/\n            \u2514\u2500\u2500 2023-05-15_Wells_Fargo_Bank_Statement.pdf\n</code></pre>"},{"location":"user-guide/#custom-patterns","title":"Custom Patterns","text":"<p>You can customize the organization patterns:</p> <p>Folder Structure Patterns: - <code>{company}/{year}/{month}</code> - Default pattern - <code>{company}/{type}/{year}</code> - Group by document type - <code>{year}/{company}/{month}</code> - Year-first organization</p> <p>Filename Patterns: - <code>{date}_{company}_{type}</code> - Default pattern - <code>{company}_{type}_{date}</code> - Company-first naming - <code>{year}_{month}_{day}_{company}_{type}</code> - Detailed naming</p>"},{"location":"user-guide/#troubleshooting","title":"Troubleshooting","text":"<p>\ud83d\udcd6 For comprehensive troubleshooting, see Troubleshooting Guide</p>"},{"location":"user-guide/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/#document-preparation","title":"Document Preparation","text":"<ol> <li>Scan Quality: Use high resolution (300 DPI minimum)</li> <li>File Format: PDF format works best</li> <li>File Size: Keep files under 50MB for optimal processing</li> <li>Text Clarity: Ensure text is readable and not skewed</li> </ol>"},{"location":"user-guide/#processing-workflow","title":"Processing Workflow","text":"<ol> <li>Test First: Always use <code>--dry-run</code> for new document types</li> <li>Batch Processing: Process similar documents together</li> <li>Review Results: Check confidence scores before final processing</li> <li>Backup: Keep original files until you're satisfied with organization</li> </ol>"},{"location":"user-guide/#security-considerations","title":"Security Considerations","text":"<ul> <li>API Keys: Never commit API keys to version control</li> <li>Local Processing: Use LM Studio for sensitive documents</li> <li>File Permissions: Ensure proper file permissions for output directories</li> <li>Network Security: Use HTTPS for cloud AI providers</li> </ul>"},{"location":"user-guide/#advanced-usage","title":"Advanced Usage","text":""},{"location":"user-guide/#custom-processing","title":"Custom Processing","text":"<pre><code>from src.ai_analyzer import AIAnalyzer\nfrom src.pdf_processor import PDFProcessor\n\n# Custom processing workflow\nanalyzer = AIAnalyzer(provider='openai')\nprocessor = PDFProcessor()\n\n# Process a single document\ndoc = processor.process_pdf('document.pdf')\nresult = analyzer.analyze_document(doc)\nprint(result.suggested_name)\n</code></pre>"},{"location":"user-guide/#integration-with-other-tools","title":"Integration with Other Tools","text":"<p>The system can be integrated with other document management tools:</p> <ul> <li>File Watchers: Monitor directories for new PDFs</li> <li>Cron Jobs: Schedule regular processing</li> <li>Webhooks: Trigger processing from other applications</li> <li>API Integration: Use the core modules in other Python applications</li> </ul>"},{"location":"user-guide/#support","title":"Support","text":"<p>\ud83d\udcd6 For additional help, see Troubleshooting Guide or create an issue on GitHub</p>"}]}